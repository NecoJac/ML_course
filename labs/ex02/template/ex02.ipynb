{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84617543, 1.7195476 , 1.85275263, ..., 1.59669981, 1.72585608,\n",
       "       1.54860615])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    e=y-tx.dot(w)\n",
    "    return sum(e*e)/(2*len(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(len(grid_w0)):\n",
    "        for j in range(len(grid_w1)):\n",
    "            losses[i,j]=compute_loss(y, tx, np.array([grid_w0[i],grid_w1[j]]))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=20.759339381144258, w0*=75.86206896551724, w1*=15.517241379310349, execution time=0.866 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=30)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6591889938705313, 0.09618339348893848)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_x, std_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient vector\n",
    "    # ***************************************************\n",
    "    e=y-tx.dot(w)\n",
    "    return -(1/len(y))*tx.T.dot(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        gradient=compute_gradient(y, tx, w)\n",
    "        loss=compute_loss(y,tx,w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w=w-gamma*gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591647, w0=7.329392200210475, w1=1.3479712434989204\n",
      "GD iter. 1/49: loss=2264.6350560300007, w0=13.92584518039996, w1=2.5611453626479217\n",
      "GD iter. 2/49: loss=1837.27771407937, w0=19.862652862570464, w1=3.653002069882027\n",
      "GD iter. 3/49: loss=1491.1182670993785, w0=25.205779776523926, w1=4.635673106392729\n",
      "GD iter. 4/49: loss=1210.729115045579, w0=30.01459399908207, w1=5.520077039252341\n",
      "GD iter. 5/49: loss=983.6139018819912, w0=34.34252679938438, w1=6.316040578826014\n",
      "GD iter. 6/49: loss=799.6505792194947, w0=38.237666319656455, w1=7.032407764442313\n",
      "GD iter. 7/49: loss=650.6402878628645, w0=41.7432918879013, w1=7.677138231496978\n",
      "GD iter. 8/49: loss=529.941951863998, w0=44.89835489932168, w1=8.257395651846178\n",
      "GD iter. 9/49: loss=432.176299704918, w0=47.73791160960005, w1=8.779627330160464\n",
      "GD iter. 10/49: loss=352.98612145605927, w0=50.29351264885055, w1=9.249635840643316\n",
      "GD iter. 11/49: loss=288.8420770744868, w0=52.59355358417602, w1=9.67264350007789\n",
      "GD iter. 12/49: loss=236.8854011254109, w0=54.66359042596894, w1=10.053350393569005\n",
      "GD iter. 13/49: loss=194.80049360666086, w0=56.52662358358257, w1=10.395986597711003\n",
      "GD iter. 14/49: loss=160.71171851647446, w0=58.20335342543483, w1=10.704359181438804\n",
      "GD iter. 15/49: loss=133.09981069342055, w0=59.71241028310187, w1=10.981894506793827\n",
      "GD iter. 16/49: loss=110.73416535674797, w0=61.0705614550022, w1=11.231676299613346\n",
      "GD iter. 17/49: loss=92.617992634044, w0=62.29289750971249, w1=11.456479913150911\n",
      "GD iter. 18/49: loss=77.94389272865314, w0=63.392999958951755, w1=11.658803165334724\n",
      "GD iter. 19/49: loss=66.0578718052866, w0=64.38309216326711, w1=11.840894092300157\n",
      "GD iter. 20/49: loss=56.43019485735963, w0=65.27417514715091, w1=12.004775926569046\n",
      "GD iter. 21/49: loss=48.631776529538854, w0=66.07614983264634, w1=12.152269577411046\n",
      "GD iter. 22/49: loss=42.31505768400418, w0=66.79792704959222, w1=12.285013863168846\n",
      "GD iter. 23/49: loss=37.198515419120916, w0=67.44752654484351, w1=12.404483720350866\n",
      "GD iter. 24/49: loss=33.054116184565494, w0=68.03216609056967, w1=12.512006591814686\n",
      "GD iter. 25/49: loss=29.697152804575754, w0=68.55834168172322, w1=12.608777176132122\n",
      "GD iter. 26/49: loss=26.978012466784076, w0=69.03189971376142, w1=12.695870702017814\n",
      "GD iter. 27/49: loss=24.775508793172673, w0=69.45810194259579, w1=12.774254875314934\n",
      "GD iter. 28/49: loss=22.99148081754748, w0=69.84168394854673, w1=12.844800631282347\n",
      "GD iter. 29/49: loss=21.546418157291, w0=70.18690775390257, w1=12.908291811653017\n",
      "GD iter. 30/49: loss=20.375917402483346, w0=70.49760917872284, w1=12.965433873986619\n",
      "GD iter. 31/49: loss=19.42781179108912, w0=70.77724046106107, w1=13.016861730086863\n",
      "GD iter. 32/49: loss=18.659846245859754, w0=71.02890861516548, w1=13.063146800577082\n",
      "GD iter. 33/49: loss=18.037794154224002, w0=71.25540995385946, w1=13.104803364018277\n",
      "GD iter. 34/49: loss=17.533931959999048, w0=71.45926115868403, w1=13.142294271115354\n",
      "GD iter. 35/49: loss=17.125803582676813, w0=71.64272724302614, w1=13.176036087502723\n",
      "GD iter. 36/49: loss=16.795219597045804, w0=71.80784671893404, w1=13.206403722251356\n",
      "GD iter. 37/49: loss=16.52744656868461, w0=71.95645424725116, w1=13.233734593525124\n",
      "GD iter. 38/49: loss=16.310550415712207, w0=72.09020102273657, w1=13.258332377671517\n",
      "GD iter. 39/49: loss=16.134864531804578, w0=72.21057312067343, w1=13.28047038340327\n",
      "GD iter. 40/49: loss=15.99255896583916, w0=72.3189080088166, w1=13.300394588561847\n",
      "GD iter. 41/49: loss=15.877291457407333, w0=72.41640940814547, w1=13.318326373204567\n",
      "GD iter. 42/49: loss=15.783924775577496, w0=72.50416066754144, w1=13.334464979383014\n",
      "GD iter. 43/49: loss=15.708297763295361, w0=72.58313680099782, w1=13.348989724943618\n",
      "GD iter. 44/49: loss=15.647039883346832, w0=72.65421532110855, w1=13.36206199594816\n",
      "GD iter. 45/49: loss=15.597421000588536, w0=72.71818598920821, w1=13.373827039852248\n",
      "GD iter. 46/49: loss=15.557229705554343, w0=72.77575959049791, w1=13.384415579365928\n",
      "GD iter. 47/49: loss=15.524674756576557, w0=72.82757583165863, w1=13.39394526492824\n",
      "GD iter. 48/49: loss=15.49830524790471, w0=72.8742104487033, w1=13.40252198193432\n",
      "GD iter. 49/49: loss=15.476945945880352, w0=72.91618160404349, w1=13.410241027239794\n",
      "GD: execution time=0.052 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba485a1af9940b6a841f67d574c916e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    e=y-tx.dot(w)\n",
    "    return -(1/len(y))*tx.T.dot(e)\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        for sgd_y, sgd_tx in batch_iter(y, tx, batch_size,num_batches=2):\n",
    "            gradient=compute_gradient(sgd_y, sgd_tx, w)\n",
    "            loss=compute_loss(sgd_y,sgd_tx,w)\n",
    "            w=w-gamma*gradient\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=1802.3573126858796, w0=10.871929270513405, w1=-11.195509450061717\n",
      "SGD iter. 1/49: loss=690.7118500307239, w0=22.980934312710023, w1=-7.3685953185459825\n",
      "SGD iter. 2/49: loss=239.26923225800854, w0=30.71526085477808, w1=-9.214925066027286\n",
      "SGD iter. 3/49: loss=686.7994100847746, w0=43.22430804574302, w1=7.525828003878685\n",
      "SGD iter. 4/49: loss=437.7282947919174, w0=49.65628507995269, w1=5.064229303926384\n",
      "SGD iter. 5/49: loss=231.24772193514417, w0=55.54709891770641, w1=9.72924868044328\n",
      "SGD iter. 6/49: loss=40.732223481300196, w0=58.758539940960446, w1=9.812966463656288\n",
      "SGD iter. 7/49: loss=40.31505640069152, w0=60.19068481171492, w1=9.635880298235442\n",
      "SGD iter. 8/49: loss=37.350457143186276, w0=62.457130405354874, w1=8.202549210962523\n",
      "SGD iter. 9/49: loss=172.9649397421498, w0=65.65556628382323, w1=7.61262876598463\n",
      "SGD iter. 10/49: loss=39.653106111564675, w0=68.61898713647982, w1=11.038569855505406\n",
      "SGD iter. 11/49: loss=0.3312470900205081, w0=69.59761902930289, w1=11.003631510559769\n",
      "SGD iter. 12/49: loss=33.51482093740708, w0=69.90891732471925, w1=11.659787117184488\n",
      "SGD iter. 13/49: loss=1.774200637161868, w0=70.77545871786255, w1=11.095069791407703\n",
      "SGD iter. 14/49: loss=61.375932886374656, w0=72.48891625617547, w1=11.7038916940083\n",
      "SGD iter. 15/49: loss=23.376184003748588, w0=70.92898628449682, w1=13.559598785408992\n",
      "SGD iter. 16/49: loss=32.750585304709816, w0=72.1034147643607, w1=14.244309264197222\n",
      "SGD iter. 17/49: loss=2.7257672462490508, w0=72.85379796776868, w1=13.831540061439002\n",
      "SGD iter. 18/49: loss=6.256865020215314, w0=73.55876644831162, w1=13.660965639335775\n",
      "SGD iter. 19/49: loss=10.216399975533392, w0=72.86140454975319, w1=13.663757576537412\n",
      "SGD iter. 20/49: loss=11.320986900464927, w0=73.49080271407725, w1=14.019191190173512\n",
      "SGD iter. 21/49: loss=3.5582843464840352, w0=74.13005499471448, w1=13.446194177140164\n",
      "SGD iter. 22/49: loss=0.5978066754740672, w0=73.63578755111652, w1=13.420114562778576\n",
      "SGD iter. 23/49: loss=49.89250269473845, w0=75.24601741864831, w1=13.099995401201921\n",
      "SGD iter. 24/49: loss=1.2906292281952405, w0=74.50188809698817, w1=13.314504858357363\n",
      "SGD iter. 25/49: loss=8.542143716350505, w0=73.70177652244702, w1=12.724849433763193\n",
      "SGD iter. 26/49: loss=1.9235868792418467, w0=73.2938598167845, w1=12.740997939542499\n",
      "SGD iter. 27/49: loss=31.15451191201299, w0=74.69019104076482, w1=13.638156859907472\n",
      "SGD iter. 28/49: loss=5.811832941191526, w0=73.66697460366849, w1=14.596263120653525\n",
      "SGD iter. 29/49: loss=38.678282107932674, w0=74.17578646292132, w1=13.66313766228206\n",
      "SGD iter. 30/49: loss=0.08314668134646576, w0=74.65729264582907, w1=13.005669466263884\n",
      "SGD iter. 31/49: loss=1.1297608805907515, w0=73.90037697749293, w1=13.505058799341407\n",
      "SGD iter. 32/49: loss=26.91123880557601, w0=74.08229188023925, w1=13.386359658182014\n",
      "SGD iter. 33/49: loss=1.6394363526747864, w0=73.7501192640972, w1=14.20265257845196\n",
      "SGD iter. 34/49: loss=32.95572714538269, w0=73.92763883575618, w1=12.680822459436452\n",
      "SGD iter. 35/49: loss=5.847867237115352, w0=73.44209838527458, w1=12.290906958189439\n",
      "SGD iter. 36/49: loss=5.760565741628908, w0=72.98851174553602, w1=12.22141615011379\n",
      "SGD iter. 37/49: loss=9.320290812423934, w0=72.97663602697429, w1=12.785557990941948\n",
      "SGD iter. 38/49: loss=0.31014720936930423, w0=72.68410073424342, w1=13.7388178609295\n",
      "SGD iter. 39/49: loss=1.2127957981189392, w0=73.37086106905302, w1=13.835302071313675\n",
      "SGD iter. 40/49: loss=35.45820146923587, w0=74.39572248675447, w1=14.347826112244004\n",
      "SGD iter. 41/49: loss=5.97303984377294, w0=73.93290979067717, w1=14.012522887111135\n",
      "SGD iter. 42/49: loss=0.5064477710520303, w0=72.73192573296846, w1=14.541550675890784\n",
      "SGD iter. 43/49: loss=3.3151681513741895, w0=72.87704947521766, w1=14.32420700151948\n",
      "SGD iter. 44/49: loss=9.59573909293709, w0=73.78488974171839, w1=14.629060868068246\n",
      "SGD iter. 45/49: loss=0.656614679502775, w0=74.05244966248812, w1=14.226470953514182\n",
      "SGD iter. 46/49: loss=4.781267127202879, w0=73.91649734345789, w1=14.442238302731605\n",
      "SGD iter. 47/49: loss=6.1583047668018605, w0=74.52769587545842, w1=14.36532626838952\n",
      "SGD iter. 48/49: loss=13.403768707414669, w0=73.77483825832492, w1=14.647737807657961\n",
      "SGD iter. 49/49: loss=1.0264534177351472, w0=73.2871809137391, w1=15.660634769306059\n",
      "SGD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e773cbc2c3fb42c1b5b01ce6b891f34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=101, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2869.8351145358542, w0=51.84746409844842, w1=7.724426406192425\n",
      "GD iter. 1/49: loss=318.2821247015965, w0=67.40170332798297, w1=10.041754328050116\n",
      "GD iter. 2/49: loss=88.64235561651282, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=67.9747763988552, w0=73.46785662750146, w1=10.9455122175746\n",
      "GD iter. 4/49: loss=66.11469426926604, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=65.94728687760302, w0=74.01381042445813, w1=11.026850427631798\n",
      "GD iter. 6/49: loss=65.93222021235334, w0=74.0516072257859, w1=11.032481534481912\n",
      "GD iter. 7/49: loss=65.93086421248086, w0=74.06294626618423, w1=11.034170866536945\n",
      "GD iter. 8/49: loss=65.93074217249234, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=65.93073118889339, w0=74.06736849193958, w1=11.034829706038408\n",
      "GD iter. 10/49: loss=65.93073020036948, w0=74.06767464603033, w1=11.034875318003895\n",
      "GD iter. 11/49: loss=65.93073011140234, w0=74.06776649225755, w1=11.034889001593541\n",
      "GD iter. 12/49: loss=65.93073010339529, w0=74.06779404612573, w1=11.034893106670431\n",
      "GD iter. 13/49: loss=65.93073010267466, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=65.93073010260976, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=65.93073010260396, w0=74.06780553608874, w1=11.034894818487496\n",
      "GD iter. 16/49: loss=65.93073010260343, w0=74.06780575927507, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=65.93073010260338, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=65.93073010260338, w0=74.06780584631775, w1=11.034894864706557\n",
      "GD iter. 19/49: loss=65.93073010260338, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=65.93073010260338, w0=74.06780585415159, w1=11.034894865873675\n",
      "GD iter. 21/49: loss=65.93073010260339, w0=74.06780585469393, w1=11.034894865954474\n",
      "GD iter. 22/49: loss=65.93073010260338, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=65.93073010260338, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=65.93073010260338, w0=74.0678058549201, w1=11.034894865988166\n",
      "GD iter. 25/49: loss=65.93073010260338, w0=74.06780585492449, w1=11.034894865988823\n",
      "GD iter. 26/49: loss=65.93073010260338, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=65.93073010260338, w0=74.06780585492619, w1=11.034894865989076\n",
      "GD iter. 28/49: loss=65.93073010260339, w0=74.06780585492632, w1=11.034894865989099\n",
      "GD iter. 29/49: loss=65.93073010260339, w0=74.06780585492635, w1=11.0348948659891\n",
      "GD iter. 30/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 31/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=65.93073010260339, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.003 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a84f82e7e8b4817afb78d347397de45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    loss=abs(y-tx.dot(w))\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    subgras=np.array([0,0])\n",
    "    for i in range(len(y)):\n",
    "        yi=y[i]\n",
    "        xi=tx[i,:]\n",
    "        e=yi-xi.dot(w)\n",
    "        if e!=0:\n",
    "\n",
    "            subgras = subgras+e/abs(e)*(-xi)\n",
    "    return subgras/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        gradient=compute_subgradient_mae(y, tx, w)\n",
    "        loss=compute_subgradient_loss(y,tx,w)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w=w-gamma*gradient\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=73.29392200210518, w0=0.7, w1=-1.5529755259535704e-15\n",
      "SubGD iter. 1/499: loss=72.59392200210517, w0=1.4, w1=-3.1059510519071408e-15\n",
      "SubGD iter. 2/499: loss=71.89392200210517, w0=2.0999999999999996, w1=-4.658926577860711e-15\n",
      "SubGD iter. 3/499: loss=71.19392200210518, w0=2.8, w1=-6.2119021038142816e-15\n",
      "SubGD iter. 4/499: loss=70.49392200210517, w0=3.5, w1=-7.764877629767851e-15\n",
      "SubGD iter. 5/499: loss=69.79392200210518, w0=4.2, w1=-9.317853155721422e-15\n",
      "SubGD iter. 6/499: loss=69.09392200210519, w0=4.9, w1=-1.0870828681674993e-14\n",
      "SubGD iter. 7/499: loss=68.39392200210517, w0=5.6000000000000005, w1=-1.2423804207628563e-14\n",
      "SubGD iter. 8/499: loss=67.69392200210518, w0=6.300000000000001, w1=-1.3976779733582134e-14\n",
      "SubGD iter. 9/499: loss=66.99392200210517, w0=7.000000000000001, w1=-1.5529755259535703e-14\n",
      "SubGD iter. 10/499: loss=66.29392200210518, w0=7.700000000000001, w1=-1.7082730785489272e-14\n",
      "SubGD iter. 11/499: loss=65.59392200210519, w0=8.4, w1=-1.863570631144284e-14\n",
      "SubGD iter. 12/499: loss=64.89392200210517, w0=9.1, w1=-2.018868183739641e-14\n",
      "SubGD iter. 13/499: loss=64.19392200210517, w0=9.799999999999999, w1=-2.174165736334998e-14\n",
      "SubGD iter. 14/499: loss=63.49392200210517, w0=10.499999999999998, w1=-2.3294632889303548e-14\n",
      "SubGD iter. 15/499: loss=62.79392200210517, w0=11.199999999999998, w1=-2.4847608415257117e-14\n",
      "SubGD iter. 16/499: loss=62.09392200210518, w0=11.899999999999997, w1=-2.6400583941210686e-14\n",
      "SubGD iter. 17/499: loss=61.393922002105185, w0=12.599999999999996, w1=-2.7953559467164255e-14\n",
      "SubGD iter. 18/499: loss=60.69392200210517, w0=13.299999999999995, w1=-2.9506534993117824e-14\n",
      "SubGD iter. 19/499: loss=59.99392200210518, w0=13.999999999999995, w1=-3.105951051907139e-14\n",
      "SubGD iter. 20/499: loss=59.293922002105184, w0=14.699999999999994, w1=-3.261248604502496e-14\n",
      "SubGD iter. 21/499: loss=58.59392200210518, w0=15.399999999999993, w1=-3.416546157097853e-14\n",
      "SubGD iter. 22/499: loss=57.893922002105185, w0=16.099999999999994, w1=-3.57184370969321e-14\n",
      "SubGD iter. 23/499: loss=57.19392200210518, w0=16.799999999999994, w1=-3.727141262288567e-14\n",
      "SubGD iter. 24/499: loss=56.49392200210518, w0=17.499999999999993, w1=-3.882438814883924e-14\n",
      "SubGD iter. 25/499: loss=55.793922002105184, w0=18.199999999999992, w1=-4.0377363674792807e-14\n",
      "SubGD iter. 26/499: loss=55.09392200210518, w0=18.89999999999999, w1=-4.1930339200746376e-14\n",
      "SubGD iter. 27/499: loss=54.393922002105185, w0=19.59999999999999, w1=-4.3483314726699945e-14\n",
      "SubGD iter. 28/499: loss=53.69392200210518, w0=20.29999999999999, w1=-4.5036290252653514e-14\n",
      "SubGD iter. 29/499: loss=52.99392200210518, w0=20.99999999999999, w1=-4.658926577860708e-14\n",
      "SubGD iter. 30/499: loss=52.293922002105184, w0=21.69999999999999, w1=-4.814224130456065e-14\n",
      "SubGD iter. 31/499: loss=51.59392200210518, w0=22.399999999999988, w1=-4.969521683051422e-14\n",
      "SubGD iter. 32/499: loss=50.893922002105185, w0=23.099999999999987, w1=-5.124819235646779e-14\n",
      "SubGD iter. 33/499: loss=50.19392200210518, w0=23.799999999999986, w1=-5.280116788242136e-14\n",
      "SubGD iter. 34/499: loss=49.49392200210518, w0=24.499999999999986, w1=-5.435414340837493e-14\n",
      "SubGD iter. 35/499: loss=48.79392200210519, w0=25.199999999999985, w1=-5.59071189343285e-14\n",
      "SubGD iter. 36/499: loss=48.09392200210519, w0=25.899999999999984, w1=-5.746009446028207e-14\n",
      "SubGD iter. 37/499: loss=47.393922002105185, w0=26.599999999999984, w1=-5.901306998623565e-14\n",
      "SubGD iter. 38/499: loss=46.6939220021052, w0=27.299999999999983, w1=-6.056604551218922e-14\n",
      "SubGD iter. 39/499: loss=45.99392200210519, w0=27.999999999999982, w1=-6.21190210381428e-14\n",
      "SubGD iter. 40/499: loss=45.29392200210519, w0=28.69999999999998, w1=-6.367199656409637e-14\n",
      "SubGD iter. 41/499: loss=44.593922002105195, w0=29.39999999999998, w1=-6.522497209004995e-14\n",
      "SubGD iter. 42/499: loss=43.89392723059967, w0=30.099859999999982, w1=0.0004404657702421764\n",
      "SubGD iter. 43/499: loss=43.194206925442394, w0=30.799719999999983, w1=0.0008809315405495777\n",
      "SubGD iter. 44/499: loss=42.494486620285116, w0=31.499579999999984, w1=0.001321397310856979\n",
      "SubGD iter. 45/499: loss=41.794801882440076, w0=32.19929999999999, w1=0.002151200058803724\n",
      "SubGD iter. 46/499: loss=41.09536078676493, w0=32.899019999999986, w1=0.002981002806750469\n",
      "SubGD iter. 47/499: loss=40.396015121762325, w0=33.59859999999998, w1=0.004238399708372432\n",
      "SubGD iter. 48/499: loss=39.696964631836686, w0=34.298039999999986, w1=0.005823822408791713\n",
      "SubGD iter. 49/499: loss=38.99808059302934, w0=34.99747999999999, w1=0.0074092451092109945\n",
      "SubGD iter. 50/499: loss=38.299196554222, w0=35.69691999999999, w1=0.008994667809630276\n",
      "SubGD iter. 51/499: loss=37.600470352601796, w0=36.39607999999999, w1=0.011248049853488248\n",
      "SubGD iter. 52/499: loss=36.90236166793368, w0=37.09495999999999, w1=0.014269124444697119\n",
      "SubGD iter. 53/499: loss=36.20468598163629, w0=37.793699999999994, w1=0.01766349946233946\n",
      "SubGD iter. 54/499: loss=35.507288901302104, w0=38.49215999999999, w1=0.021587972991156293\n",
      "SubGD iter. 55/499: loss=34.81047272559701, w0=39.19019999999999, w1=0.026549981650513393\n",
      "SubGD iter. 56/499: loss=34.11463938511051, w0=39.88739999999999, w1=0.0334590206309035\n",
      "SubGD iter. 57/499: loss=33.42034933030703, w0=40.584039999999995, w1=0.04155352991358485\n",
      "SubGD iter. 58/499: loss=32.72708260590542, w0=41.28025999999999, w1=0.05080738787870366\n",
      "SubGD iter. 59/499: loss=32.035274191106154, w0=41.97507999999999, w1=0.06316953459264504\n",
      "SubGD iter. 60/499: loss=31.346253501120472, w0=42.667939999999994, w1=0.07970663453187159\n",
      "SubGD iter. 61/499: loss=30.66081118573862, w0=43.35925999999999, w1=0.09929003796957596\n",
      "SubGD iter. 62/499: loss=29.97824373392408, w0=44.04889999999999, w1=0.12249682042556717\n",
      "SubGD iter. 63/499: loss=29.29919217002557, w0=44.735739999999986, w1=0.15117673515145405\n",
      "SubGD iter. 64/499: loss=28.625370150150545, w0=45.41991999999998, w1=0.1848471294408023\n",
      "SubGD iter. 65/499: loss=27.95640812788488, w0=46.10073999999998, w1=0.22490170464881898\n",
      "SubGD iter. 66/499: loss=27.293211335702274, w0=46.77847999999998, w1=0.27030807598900264\n",
      "SubGD iter. 67/499: loss=26.635946775492176, w0=47.45243999999998, w1=0.32205641313644706\n",
      "SubGD iter. 68/499: loss=25.986354455661576, w0=48.119959999999985, w1=0.3843602843516495\n",
      "SubGD iter. 69/499: loss=25.34635990054962, w0=48.78257999999998, w1=0.45460143187065083\n",
      "SubGD iter. 70/499: loss=24.713407766391825, w0=49.44141999999998, w1=0.5311991534378644\n",
      "SubGD iter. 71/499: loss=24.086931144489547, w0=50.094659999999976, w1=0.6167864550871748\n",
      "SubGD iter. 72/499: loss=23.469061835298344, w0=50.74159999999998, w1=0.7118294204257005\n",
      "SubGD iter. 73/499: loss=22.860312219449888, w0=51.382239999999975, w1=0.8163783816188553\n",
      "SubGD iter. 74/499: loss=22.260394194603613, w0=52.015879999999974, w1=0.9309819479180104\n",
      "SubGD iter. 75/499: loss=21.670214357989362, w0=52.64223999999997, w1=1.056041039445561\n",
      "SubGD iter. 76/499: loss=21.089713092061302, w0=53.261179999999975, w1=1.1909782249707368\n",
      "SubGD iter. 77/499: loss=20.51839520029387, w0=53.87353999999998, w1=1.3354326069268716\n",
      "SubGD iter. 78/499: loss=19.954842019021974, w0=54.479039999999976, w1=1.488859155423101\n",
      "SubGD iter. 79/499: loss=19.39981727796524, w0=55.07641999999998, w1=1.6526057998941344\n",
      "SubGD iter. 80/499: loss=18.854292127308746, w0=55.664699999999975, w1=1.827199911738537\n",
      "SubGD iter. 81/499: loss=18.31878394789317, w0=56.24345999999998, w1=2.013212915976214\n",
      "SubGD iter. 82/499: loss=17.792491479525168, w0=56.81479999999998, w1=2.2075986497860063\n",
      "SubGD iter. 83/499: loss=17.27474434540427, w0=57.37633999999998, w1=2.411376270974464\n",
      "SubGD iter. 84/499: loss=16.766906752678832, w0=57.92975999999998, w1=2.6230481013704767\n",
      "SubGD iter. 85/499: loss=16.267994479749298, w0=58.47407999999998, w1=2.8433267790651087\n",
      "SubGD iter. 86/499: loss=15.777334186667382, w0=59.00957999999998, w1=3.072330965520354\n",
      "SubGD iter. 87/499: loss=15.294906834780795, w0=59.53569999999998, w1=3.3102924945409007\n",
      "SubGD iter. 88/499: loss=14.820404573025089, w0=60.053559999999976, w1=3.555351748353824\n",
      "SubGD iter. 89/499: loss=14.354283714893946, w0=60.559939999999976, w1=3.809170691886062\n",
      "SubGD iter. 90/499: loss=13.898001392894923, w0=61.057499999999976, w1=4.069720751433983\n",
      "SubGD iter. 91/499: loss=13.44882382810378, w0=61.547919999999976, w1=4.335508393726905\n",
      "SubGD iter. 92/499: loss=13.006044196344101, w0=62.02965999999998, w1=4.6069897470010375\n",
      "SubGD iter. 93/499: loss=12.57110174936068, w0=62.502719999999975, w1=4.88502014251682\n",
      "SubGD iter. 94/499: loss=12.143380485959392, w0=62.96583999999997, w1=5.16875462665388\n",
      "SubGD iter. 95/499: loss=11.723894837245583, w0=63.41971999999997, w1=5.456484559032046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 96/499: loss=11.313435023601551, w0=63.86463999999997, w1=5.747997496770113\n",
      "SubGD iter. 97/499: loss=10.911156920015099, w0=64.30129999999997, w1=6.043221223968383\n",
      "SubGD iter. 98/499: loss=10.516948122608078, w0=64.72773999999997, w1=6.340354080836923\n",
      "SubGD iter. 99/499: loss=10.13359513103867, w0=65.14381999999996, w1=6.63994524590634\n",
      "SubGD iter. 100/499: loss=9.760677429923486, w0=65.54995999999996, w1=6.939754306256994\n",
      "SubGD iter. 101/499: loss=9.398674623189937, w0=65.94755999999995, w1=7.240382293155359\n",
      "SubGD iter. 102/499: loss=9.046552477133655, w0=66.33451999999996, w1=7.542759507922872\n",
      "SubGD iter. 103/499: loss=8.704760514732415, w0=66.71139999999995, w1=7.846017516367578\n",
      "SubGD iter. 104/499: loss=8.372871671628266, w0=67.07791999999995, w1=8.149168076773346\n",
      "SubGD iter. 105/499: loss=8.052713872262597, w0=67.43603999999995, w1=8.450471378640396\n",
      "SubGD iter. 106/499: loss=7.741845358498816, w0=67.78645999999995, w1=8.751045452661094\n",
      "SubGD iter. 107/499: loss=7.440636497847948, w0=68.12511999999995, w1=9.04921572225288\n",
      "SubGD iter. 108/499: loss=7.152144892432378, w0=68.45537999999995, w1=9.343976087699637\n",
      "SubGD iter. 109/499: loss=6.874953545674702, w0=68.77695999999995, w1=9.635092372673002\n",
      "SubGD iter. 110/499: loss=6.609759691657253, w0=69.08803999999995, w1=9.919493282073365\n",
      "SubGD iter. 111/499: loss=6.359664465347405, w0=69.38749999999995, w1=10.197623582279002\n",
      "SubGD iter. 112/499: loss=6.125559830337084, w0=69.67281999999994, w1=10.46806359361339\n",
      "SubGD iter. 113/499: loss=5.908756851126104, w0=69.94651999999995, w1=10.728826346302005\n",
      "SubGD iter. 114/499: loss=5.708346277966668, w0=70.20887999999995, w1=10.979299692022279\n",
      "SubGD iter. 115/499: loss=5.524903595719347, w0=70.45653999999995, w1=11.220392679253374\n",
      "SubGD iter. 116/499: loss=5.358572110476778, w0=70.69215999999994, w1=11.449066352016724\n",
      "SubGD iter. 117/499: loss=5.208366578733325, w0=70.91545999999994, w1=11.66451264164341\n",
      "SubGD iter. 118/499: loss=5.075452050918035, w0=71.12447999999993, w1=11.864387168308943\n",
      "SubGD iter. 119/499: loss=4.960839914882402, w0=71.31865999999994, w1=12.045105403559484\n",
      "SubGD iter. 120/499: loss=4.864240181709682, w0=71.49939999999994, w1=12.20983607316598\n",
      "SubGD iter. 121/499: loss=4.782724768945261, w0=71.66543999999993, w1=12.357476521898722\n",
      "SubGD iter. 122/499: loss=4.715208074668135, w0=71.81593999999993, w1=12.48980888194029\n",
      "SubGD iter. 123/499: loss=4.660146063774253, w0=71.95369999999993, w1=12.612418157319299\n",
      "SubGD iter. 124/499: loss=4.6138484530642225, w0=72.08067999999993, w1=12.721366944472148\n",
      "SubGD iter. 125/499: loss=4.576038370591764, w0=72.19435999999993, w1=12.815458765817613\n",
      "SubGD iter. 126/499: loss=4.5466498510490405, w0=72.29697999999993, w1=12.90059276939534\n",
      "SubGD iter. 127/499: loss=4.522563544988974, w0=72.38965999999994, w1=12.97576965427992\n",
      "SubGD iter. 128/499: loss=4.503077398110059, w0=72.47435999999993, w1=13.04396334930227\n",
      "SubGD iter. 129/499: loss=4.487012427842286, w0=72.55093999999994, w1=13.103277584601688\n",
      "SubGD iter. 130/499: loss=4.474309393425119, w0=72.62051999999994, w1=13.156032035188144\n",
      "SubGD iter. 131/499: loss=4.464166669156606, w0=72.68239999999994, w1=13.201870566969161\n",
      "SubGD iter. 132/499: loss=4.456202124936147, w0=72.73769999999995, w1=13.241365939188695\n",
      "SubGD iter. 133/499: loss=4.449913837301208, w0=72.78823999999994, w1=13.276636749385748\n",
      "SubGD iter. 134/499: loss=4.4447394482327685, w0=72.83401999999994, w1=13.308112586749687\n",
      "SubGD iter. 135/499: loss=4.440577063150134, w0=72.87447999999993, w1=13.335151520405006\n",
      "SubGD iter. 136/499: loss=4.4373967610583085, w0=72.91115999999994, w1=13.358430829065458\n",
      "SubGD iter. 137/499: loss=4.4348465287075, w0=72.94447999999994, w1=13.379256780851263\n",
      "SubGD iter. 138/499: loss=4.432811551436954, w0=72.97401999999994, w1=13.396406376905544\n",
      "SubGD iter. 139/499: loss=4.431233661858322, w0=73.00103999999993, w1=13.41218912045937\n",
      "SubGD iter. 140/499: loss=4.429913776135237, w0=73.02483999999993, w1=13.425274895313084\n",
      "SubGD iter. 141/499: loss=4.428916084676415, w0=73.04625999999993, w1=13.436222021322303\n",
      "SubGD iter. 142/499: loss=4.42811221458972, w0=73.06613999999993, w1=13.447440046601253\n",
      "SubGD iter. 143/499: loss=4.427409042227934, w0=73.08405999999994, w1=13.457856669597893\n",
      "SubGD iter. 144/499: loss=4.426825784996949, w0=73.10029999999993, w1=13.467335162734873\n",
      "SubGD iter. 145/499: loss=4.426369603365169, w0=73.11401999999994, w1=13.475393628220223\n",
      "SubGD iter. 146/499: loss=4.426030178383453, w0=73.12619999999994, w1=13.482212864437892\n",
      "SubGD iter. 147/499: loss=4.425766799370374, w0=73.13697999999994, w1=13.48799725691146\n",
      "SubGD iter. 148/499: loss=4.425555929007912, w0=73.14747999999993, w1=13.493479439140252\n",
      "SubGD iter. 149/499: loss=4.425362490640805, w0=73.15699999999993, w1=13.498468271254364\n",
      "SubGD iter. 150/499: loss=4.425203617363585, w0=73.16595999999993, w1=13.50294680429713\n",
      "SubGD iter. 151/499: loss=4.425068527947261, w0=73.17365999999993, w1=13.506576029236252\n",
      "SubGD iter. 152/499: loss=4.424972782434856, w0=73.18009999999992, w1=13.509768665455107\n",
      "SubGD iter. 153/499: loss=4.424903121175712, w0=73.18597999999993, w1=13.512571468366584\n",
      "SubGD iter. 154/499: loss=4.424846327975846, w0=73.19143999999993, w1=13.515117410468855\n",
      "SubGD iter. 155/499: loss=4.42479923253376, w0=73.19605999999993, w1=13.517185961787685\n",
      "SubGD iter. 156/499: loss=4.424766409404, w0=73.19969999999994, w1=13.518069930874283\n",
      "SubGD iter. 157/499: loss=4.424747663519319, w0=73.20291999999993, w1=13.518854137767013\n",
      "SubGD iter. 158/499: loss=4.424732182668888, w0=73.20599999999993, w1=13.51952983926887\n",
      "SubGD iter. 159/499: loss=4.424717978422431, w0=73.20907999999993, w1=13.520205540770727\n",
      "SubGD iter. 160/499: loss=4.424704053977274, w0=73.21201999999992, w1=13.521000216270515\n",
      "SubGD iter. 161/499: loss=4.4246908038213455, w0=73.21495999999992, w1=13.521794891770304\n",
      "SubGD iter. 162/499: loss=4.424678207991666, w0=73.21747999999992, w1=13.522407209546943\n",
      "SubGD iter. 163/499: loss=4.424668911605651, w0=73.21985999999993, w1=13.522732908460886\n",
      "SubGD iter. 164/499: loss=4.424660947850395, w0=73.22181999999992, w1=13.522991164028737\n",
      "SubGD iter. 165/499: loss=4.424655537307837, w0=73.22363999999992, w1=13.523086524955808\n",
      "SubGD iter. 166/499: loss=4.424651183353665, w0=73.22503999999992, w1=13.522757010157395\n",
      "SubGD iter. 167/499: loss=4.424648228239375, w0=73.22643999999993, w1=13.522427495358983\n",
      "SubGD iter. 168/499: loss=4.424645273125086, w0=73.22783999999993, w1=13.52209798056057\n",
      "SubGD iter. 169/499: loss=4.424642498283796, w0=73.22895999999993, w1=13.522225963141242\n",
      "SubGD iter. 170/499: loss=4.424640682884452, w0=73.23007999999993, w1=13.522353945721914\n",
      "SubGD iter. 171/499: loss=4.424638867485107, w0=73.23119999999993, w1=13.522481928302586\n",
      "SubGD iter. 172/499: loss=4.424637300852184, w0=73.23189999999992, w1=13.523013495747021\n",
      "SubGD iter. 173/499: loss=4.424636258655271, w0=73.23273999999992, w1=13.52326627956579\n",
      "SubGD iter. 174/499: loss=4.424635339412463, w0=73.23329999999991, w1=13.523741235074766\n",
      "SubGD iter. 175/499: loss=4.424634640448436, w0=73.23399999999991, w1=13.523937406958076\n",
      "SubGD iter. 176/499: loss=4.424633962890472, w0=73.2345599999999, w1=13.523888604707691\n",
      "SubGD iter. 177/499: loss=4.424633633499305, w0=73.23497999999991, w1=13.524118586082972\n",
      "SubGD iter. 178/499: loss=4.424633305940116, w0=73.23539999999991, w1=13.524348567458253\n",
      "SubGD iter. 179/499: loss=4.424632978380924, w0=73.23581999999992, w1=13.524578548833533\n",
      "SubGD iter. 180/499: loss=4.424632650821734, w0=73.23623999999992, w1=13.524808530208814\n",
      "SubGD iter. 181/499: loss=4.424632389924093, w0=73.23651999999993, w1=13.524964267899264\n",
      "SubGD iter. 182/499: loss=4.424632243275195, w0=73.23679999999993, w1=13.525120005589715\n",
      "SubGD iter. 183/499: loss=4.424632096626298, w0=73.23707999999993, w1=13.525275743280165\n",
      "SubGD iter. 184/499: loss=4.424631993328702, w0=73.23721999999994, w1=13.525174424196196\n",
      "SubGD iter. 185/499: loss=4.424631950663619, w0=73.23735999999994, w1=13.525073105112227\n",
      "SubGD iter. 186/499: loss=4.424631907998538, w0=73.23749999999994, w1=13.524971786028258\n",
      "SubGD iter. 187/499: loss=4.424631865333457, w0=73.23763999999994, w1=13.52487046694429\n",
      "SubGD iter. 188/499: loss=4.424631822668376, w0=73.23777999999994, w1=13.52476914786032\n",
      "SubGD iter. 189/499: loss=4.4246317826859745, w0=73.23805999999995, w1=13.52492488555077\n",
      "SubGD iter. 190/499: loss=4.42463174654501, w0=73.23819999999995, w1=13.524823566466802\n",
      "SubGD iter. 191/499: loss=4.424631703879928, w0=73.23833999999995, w1=13.524722247382833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 192/499: loss=4.424631661214848, w0=73.23847999999995, w1=13.524620928298864\n",
      "SubGD iter. 193/499: loss=4.424631622214842, w0=73.23847999999995, w1=13.524586781150308\n",
      "SubGD iter. 194/499: loss=4.424631620549089, w0=73.23847999999995, w1=13.524552634001752\n",
      "SubGD iter. 195/499: loss=4.424631618883335, w0=73.23847999999995, w1=13.524518486853196\n",
      "SubGD iter. 196/499: loss=4.424631617217582, w0=73.23847999999995, w1=13.52448433970464\n",
      "SubGD iter. 197/499: loss=4.424631615551827, w0=73.23847999999995, w1=13.524450192556085\n",
      "SubGD iter. 198/499: loss=4.424631613886072, w0=73.23847999999995, w1=13.524416045407529\n",
      "SubGD iter. 199/499: loss=4.4246316122203195, w0=73.23847999999995, w1=13.524381898258973\n",
      "SubGD iter. 200/499: loss=4.424631615444577, w0=73.23861999999995, w1=13.524604807884836\n",
      "SubGD iter. 201/499: loss=4.424631621428463, w0=73.23861999999995, w1=13.52457066073628\n",
      "SubGD iter. 202/499: loss=4.424631619762709, w0=73.23861999999995, w1=13.524536513587725\n",
      "SubGD iter. 203/499: loss=4.424631618096955, w0=73.23861999999995, w1=13.524502366439169\n",
      "SubGD iter. 204/499: loss=4.424631616431201, w0=73.23861999999995, w1=13.524468219290613\n",
      "SubGD iter. 205/499: loss=4.424631614765448, w0=73.23861999999995, w1=13.524434072142057\n",
      "SubGD iter. 206/499: loss=4.4246316130996926, w0=73.23861999999995, w1=13.524399924993501\n",
      "SubGD iter. 207/499: loss=4.42463161143394, w0=73.23861999999995, w1=13.524365777844945\n",
      "SubGD iter. 208/499: loss=4.424631609768185, w0=73.23861999999995, w1=13.52433163069639\n",
      "SubGD iter. 209/499: loss=4.42463160810243, w0=73.23861999999995, w1=13.524297483547834\n",
      "SubGD iter. 210/499: loss=4.4246316143257935, w0=73.23875999999996, w1=13.524520393173697\n",
      "SubGD iter. 211/499: loss=4.424631617310575, w0=73.23875999999996, w1=13.524486246025141\n",
      "SubGD iter. 212/499: loss=4.424631615644821, w0=73.23875999999996, w1=13.524452098876585\n",
      "SubGD iter. 213/499: loss=4.4246316139790665, w0=73.23875999999996, w1=13.52441795172803\n",
      "SubGD iter. 214/499: loss=4.424631612313314, w0=73.23875999999996, w1=13.524383804579474\n",
      "SubGD iter. 215/499: loss=4.424631610647559, w0=73.23875999999996, w1=13.524349657430918\n",
      "SubGD iter. 216/499: loss=4.424631608981806, w0=73.23875999999996, w1=13.524315510282362\n",
      "SubGD iter. 217/499: loss=4.424631607316051, w0=73.23875999999996, w1=13.524281363133806\n",
      "SubGD iter. 218/499: loss=4.424631605650297, w0=73.23875999999996, w1=13.52424721598525\n",
      "SubGD iter. 219/499: loss=4.424631603984543, w0=73.23875999999996, w1=13.524213068836694\n",
      "SubGD iter. 220/499: loss=4.42463161320701, w0=73.23889999999996, w1=13.524435978462558\n",
      "SubGD iter. 221/499: loss=4.424631613192687, w0=73.23889999999996, w1=13.524401831314002\n",
      "SubGD iter. 222/499: loss=4.424631611526932, w0=73.23889999999996, w1=13.524367684165446\n",
      "SubGD iter. 223/499: loss=4.424631609861179, w0=73.23889999999996, w1=13.52433353701689\n",
      "SubGD iter. 224/499: loss=4.4246316081954244, w0=73.23889999999996, w1=13.524299389868334\n",
      "SubGD iter. 225/499: loss=4.424631606529671, w0=73.23889999999996, w1=13.524265242719778\n",
      "SubGD iter. 226/499: loss=4.424631604863916, w0=73.23889999999996, w1=13.524231095571222\n",
      "SubGD iter. 227/499: loss=4.424631603198163, w0=73.23889999999996, w1=13.524196948422667\n",
      "SubGD iter. 228/499: loss=4.4246316015324085, w0=73.23889999999996, w1=13.52416280127411\n",
      "SubGD iter. 229/499: loss=4.4246316012143305, w0=73.23903999999996, w1=13.524385710899974\n",
      "SubGD iter. 230/499: loss=4.424631610740552, w0=73.23903999999996, w1=13.524351563751418\n",
      "SubGD iter. 231/499: loss=4.424631609074798, w0=73.23903999999996, w1=13.524317416602862\n",
      "SubGD iter. 232/499: loss=4.424631607409045, w0=73.23903999999996, w1=13.524283269454306\n",
      "SubGD iter. 233/499: loss=4.42463160574329, w0=73.23903999999996, w1=13.52424912230575\n",
      "SubGD iter. 234/499: loss=4.424631604077537, w0=73.23903999999996, w1=13.524214975157195\n",
      "SubGD iter. 235/499: loss=4.424631602411783, w0=73.23903999999996, w1=13.524180828008639\n",
      "SubGD iter. 236/499: loss=4.42463160074603, w0=73.23903999999996, w1=13.524146680860083\n",
      "SubGD iter. 237/499: loss=4.424631599080274, w0=73.23903999999996, w1=13.524112533711527\n",
      "SubGD iter. 238/499: loss=4.424631597414521, w0=73.23903999999996, w1=13.524078386562971\n",
      "SubGD iter. 239/499: loss=4.424631600095546, w0=73.23917999999996, w1=13.524301296188835\n",
      "SubGD iter. 240/499: loss=4.424631606622665, w0=73.23917999999996, w1=13.524267149040279\n",
      "SubGD iter. 241/499: loss=4.42463160495691, w0=73.23917999999996, w1=13.524233001891723\n",
      "SubGD iter. 242/499: loss=4.4246316032911555, w0=73.23917999999996, w1=13.524198854743167\n",
      "SubGD iter. 243/499: loss=4.424631601625403, w0=73.23917999999996, w1=13.524164707594611\n",
      "SubGD iter. 244/499: loss=4.424631599959648, w0=73.23917999999996, w1=13.524130560446055\n",
      "SubGD iter. 245/499: loss=4.424631598293895, w0=73.23917999999996, w1=13.5240964132975\n",
      "SubGD iter. 246/499: loss=4.42463159662814, w0=73.23917999999996, w1=13.524062266148944\n",
      "SubGD iter. 247/499: loss=4.424631594962388, w0=73.23917999999996, w1=13.524028119000388\n",
      "SubGD iter. 248/499: loss=4.424631593296633, w0=73.23917999999996, w1=13.523993971851832\n",
      "SubGD iter. 249/499: loss=4.424631598976763, w0=73.23931999999996, w1=13.524216881477695\n",
      "SubGD iter. 250/499: loss=4.424631602504776, w0=73.23931999999996, w1=13.52418273432914\n",
      "SubGD iter. 251/499: loss=4.424631600839022, w0=73.23931999999996, w1=13.524148587180584\n",
      "SubGD iter. 252/499: loss=4.424631599173268, w0=73.23931999999996, w1=13.524114440032028\n",
      "SubGD iter. 253/499: loss=4.4246315975075134, w0=73.23931999999996, w1=13.524080292883472\n",
      "SubGD iter. 254/499: loss=4.424631595841761, w0=73.23931999999996, w1=13.524046145734916\n",
      "SubGD iter. 255/499: loss=4.424631594176007, w0=73.23931999999996, w1=13.52401199858636\n",
      "SubGD iter. 256/499: loss=4.424631592510252, w0=73.23931999999996, w1=13.523977851437804\n",
      "SubGD iter. 257/499: loss=4.424631590844498, w0=73.23931999999996, w1=13.523943704289248\n",
      "SubGD iter. 258/499: loss=4.424631589178745, w0=73.23931999999996, w1=13.523909557140692\n",
      "SubGD iter. 259/499: loss=4.42463159785798, w0=73.23945999999997, w1=13.524132466766556\n",
      "SubGD iter. 260/499: loss=4.424631598386888, w0=73.23945999999997, w1=13.524098319618\n",
      "SubGD iter. 261/499: loss=4.424631596721134, w0=73.23945999999997, w1=13.524064172469444\n",
      "SubGD iter. 262/499: loss=4.42463159505538, w0=73.23945999999997, w1=13.524030025320888\n",
      "SubGD iter. 263/499: loss=4.424631593389626, w0=73.23945999999997, w1=13.523995878172332\n",
      "SubGD iter. 264/499: loss=4.424631591723872, w0=73.23945999999997, w1=13.523961731023777\n",
      "SubGD iter. 265/499: loss=4.4246315900581195, w0=73.23945999999997, w1=13.52392758387522\n",
      "SubGD iter. 266/499: loss=4.424631588392364, w0=73.23945999999997, w1=13.523893436726665\n",
      "SubGD iter. 267/499: loss=4.42463158672661, w0=73.23945999999997, w1=13.523859289578109\n",
      "SubGD iter. 268/499: loss=4.424631585865299, w0=73.23959999999997, w1=13.524082199203972\n",
      "SubGD iter. 269/499: loss=4.424631595934754, w0=73.23959999999997, w1=13.524048052055416\n",
      "SubGD iter. 270/499: loss=4.424631594269001, w0=73.23959999999997, w1=13.52401390490686\n",
      "SubGD iter. 271/499: loss=4.424631592603246, w0=73.23959999999997, w1=13.523979757758305\n",
      "SubGD iter. 272/499: loss=4.424631590937492, w0=73.23959999999997, w1=13.523945610609749\n",
      "SubGD iter. 273/499: loss=4.424631589271739, w0=73.23959999999997, w1=13.523911463461193\n",
      "SubGD iter. 274/499: loss=4.424631587605984, w0=73.23959999999997, w1=13.523877316312637\n",
      "SubGD iter. 275/499: loss=4.424631585940229, w0=73.23959999999997, w1=13.523843169164081\n",
      "SubGD iter. 276/499: loss=4.424631584274477, w0=73.23959999999997, w1=13.523809022015525\n",
      "SubGD iter. 277/499: loss=4.424631582608722, w0=73.23959999999997, w1=13.52377487486697\n",
      "SubGD iter. 278/499: loss=4.424631584746517, w0=73.23973999999997, w1=13.523997784492833\n",
      "SubGD iter. 279/499: loss=4.424631591816865, w0=73.23973999999997, w1=13.523963637344277\n",
      "SubGD iter. 280/499: loss=4.424631590151113, w0=73.23973999999997, w1=13.523929490195721\n",
      "SubGD iter. 281/499: loss=4.424631588485357, w0=73.23973999999997, w1=13.523895343047165\n",
      "SubGD iter. 282/499: loss=4.424631586819605, w0=73.23973999999997, w1=13.52386119589861\n",
      "SubGD iter. 283/499: loss=4.4246315851538505, w0=73.23973999999997, w1=13.523827048750054\n",
      "SubGD iter. 284/499: loss=4.424631583488096, w0=73.23973999999997, w1=13.523792901601498\n",
      "SubGD iter. 285/499: loss=4.424631581822343, w0=73.23973999999997, w1=13.523758754452942\n",
      "SubGD iter. 286/499: loss=4.424631580156588, w0=73.23973999999997, w1=13.523724607304386\n",
      "SubGD iter. 287/499: loss=4.4246315784908345, w0=73.23973999999997, w1=13.52369046015583\n",
      "SubGD iter. 288/499: loss=4.424631583627733, w0=73.23987999999997, w1=13.523913369781694\n",
      "SubGD iter. 289/499: loss=4.424631587698978, w0=73.23987999999997, w1=13.523879222633138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 290/499: loss=4.4246315860332235, w0=73.23987999999997, w1=13.523845075484582\n",
      "SubGD iter. 291/499: loss=4.424631584367469, w0=73.23987999999997, w1=13.523810928336026\n",
      "SubGD iter. 292/499: loss=4.424631582701716, w0=73.23987999999997, w1=13.52377678118747\n",
      "SubGD iter. 293/499: loss=4.424631581035962, w0=73.23987999999997, w1=13.523742634038914\n",
      "SubGD iter. 294/499: loss=4.424631579370208, w0=73.23987999999997, w1=13.523708486890358\n",
      "SubGD iter. 295/499: loss=4.424631577704453, w0=73.23987999999997, w1=13.523674339741802\n",
      "SubGD iter. 296/499: loss=4.4246315760387, w0=73.23987999999997, w1=13.523640192593247\n",
      "SubGD iter. 297/499: loss=4.424631574372945, w0=73.23987999999997, w1=13.52360604544469\n",
      "SubGD iter. 298/499: loss=4.424631582508949, w0=73.24001999999997, w1=13.523828955070554\n",
      "SubGD iter. 299/499: loss=4.424631583581089, w0=73.24001999999997, w1=13.523794807921998\n",
      "SubGD iter. 300/499: loss=4.424631581915335, w0=73.24001999999997, w1=13.523760660773442\n",
      "SubGD iter. 301/499: loss=4.4246315802495815, w0=73.24001999999997, w1=13.523726513624887\n",
      "SubGD iter. 302/499: loss=4.424631578583828, w0=73.24001999999997, w1=13.52369236647633\n",
      "SubGD iter. 303/499: loss=4.424631576918073, w0=73.24001999999997, w1=13.523658219327775\n",
      "SubGD iter. 304/499: loss=4.42463157525232, w0=73.24001999999997, w1=13.523624072179219\n",
      "SubGD iter. 305/499: loss=4.4246315735865664, w0=73.24001999999997, w1=13.523589925030663\n",
      "SubGD iter. 306/499: loss=4.424631571920813, w0=73.24001999999997, w1=13.523555777882107\n",
      "SubGD iter. 307/499: loss=4.424631570516268, w0=73.24015999999997, w1=13.52377868750797\n",
      "SubGD iter. 308/499: loss=4.424631581128955, w0=73.24015999999997, w1=13.523744540359415\n",
      "SubGD iter. 309/499: loss=4.424631579463202, w0=73.24015999999997, w1=13.523710393210859\n",
      "SubGD iter. 310/499: loss=4.424631577797447, w0=73.24015999999997, w1=13.523676246062303\n",
      "SubGD iter. 311/499: loss=4.424631576131694, w0=73.24015999999997, w1=13.523642098913747\n",
      "SubGD iter. 312/499: loss=4.4246315744659395, w0=73.24015999999997, w1=13.523607951765191\n",
      "SubGD iter. 313/499: loss=4.424631572800186, w0=73.24015999999997, w1=13.523573804616635\n",
      "SubGD iter. 314/499: loss=4.424631571134432, w0=73.24015999999997, w1=13.52353965746808\n",
      "SubGD iter. 315/499: loss=4.424631569468677, w0=73.24015999999997, w1=13.523505510319524\n",
      "SubGD iter. 316/499: loss=4.424631567802924, w0=73.24015999999997, w1=13.523471363170968\n",
      "SubGD iter. 317/499: loss=4.424631569397486, w0=73.24029999999998, w1=13.523694272796831\n",
      "SubGD iter. 318/499: loss=4.424631577011067, w0=73.24029999999998, w1=13.523660125648275\n",
      "SubGD iter. 319/499: loss=4.4246315753453125, w0=73.24029999999998, w1=13.52362597849972\n",
      "SubGD iter. 320/499: loss=4.4246315736795605, w0=73.24029999999998, w1=13.523591831351164\n",
      "SubGD iter. 321/499: loss=4.424631572013805, w0=73.24029999999998, w1=13.523557684202608\n",
      "SubGD iter. 322/499: loss=4.424631570348052, w0=73.24029999999998, w1=13.523523537054052\n",
      "SubGD iter. 323/499: loss=4.4246315686822975, w0=73.24029999999998, w1=13.523489389905496\n",
      "SubGD iter. 324/499: loss=4.424631567016544, w0=73.24029999999998, w1=13.52345524275694\n",
      "SubGD iter. 325/499: loss=4.42463156535079, w0=73.24029999999998, w1=13.523421095608384\n",
      "SubGD iter. 326/499: loss=4.424631563685035, w0=73.24029999999998, w1=13.523386948459828\n",
      "SubGD iter. 327/499: loss=4.424631568278702, w0=73.24043999999998, w1=13.523609858085692\n",
      "SubGD iter. 328/499: loss=4.42463157289318, w0=73.24043999999998, w1=13.523575710937136\n",
      "SubGD iter. 329/499: loss=4.424631571227425, w0=73.24043999999998, w1=13.52354156378858\n",
      "SubGD iter. 330/499: loss=4.424631569561671, w0=73.24043999999998, w1=13.523507416640024\n",
      "SubGD iter. 331/499: loss=4.424631567895917, w0=73.24043999999998, w1=13.523473269491468\n",
      "SubGD iter. 332/499: loss=4.424631566230163, w0=73.24043999999998, w1=13.523439122342912\n",
      "SubGD iter. 333/499: loss=4.424631564564409, w0=73.24043999999998, w1=13.523404975194357\n",
      "SubGD iter. 334/499: loss=4.4246315628986554, w0=73.24043999999998, w1=13.5233708280458\n",
      "SubGD iter. 335/499: loss=4.424631561232901, w0=73.24043999999998, w1=13.523336680897245\n",
      "SubGD iter. 336/499: loss=4.424631559567148, w0=73.24043999999998, w1=13.523302533748689\n",
      "SubGD iter. 337/499: loss=4.424631567159919, w0=73.24057999999998, w1=13.523525443374552\n",
      "SubGD iter. 338/499: loss=4.424631568775291, w0=73.24057999999998, w1=13.523491296225997\n",
      "SubGD iter. 339/499: loss=4.424631567109538, w0=73.24057999999998, w1=13.52345714907744\n",
      "SubGD iter. 340/499: loss=4.424631565443783, w0=73.24057999999998, w1=13.523423001928885\n",
      "SubGD iter. 341/499: loss=4.424631563778029, w0=73.24057999999998, w1=13.523388854780329\n",
      "SubGD iter. 342/499: loss=4.424631562112276, w0=73.24057999999998, w1=13.523354707631773\n",
      "SubGD iter. 343/499: loss=4.424631560446521, w0=73.24057999999998, w1=13.523320560483217\n",
      "SubGD iter. 344/499: loss=4.424631558780767, w0=73.24057999999998, w1=13.523286413334661\n",
      "SubGD iter. 345/499: loss=4.424631557115013, w0=73.24057999999998, w1=13.523252266186105\n",
      "SubGD iter. 346/499: loss=4.424631555449259, w0=73.24057999999998, w1=13.52321811903755\n",
      "SubGD iter. 347/499: loss=4.4246315660411355, w0=73.24071999999998, w1=13.523441028663413\n",
      "SubGD iter. 348/499: loss=4.424631564657403, w0=73.24071999999998, w1=13.523406881514857\n",
      "SubGD iter. 349/499: loss=4.4246315629916495, w0=73.24071999999998, w1=13.523372734366301\n",
      "SubGD iter. 350/499: loss=4.424631561325894, w0=73.24071999999998, w1=13.523338587217745\n",
      "SubGD iter. 351/499: loss=4.424631559660142, w0=73.24071999999998, w1=13.52330444006919\n",
      "SubGD iter. 352/499: loss=4.4246315579943865, w0=73.24071999999998, w1=13.523270292920634\n",
      "SubGD iter. 353/499: loss=4.424631556328634, w0=73.24071999999998, w1=13.523236145772078\n",
      "SubGD iter. 354/499: loss=4.424631554662879, w0=73.24071999999998, w1=13.523201998623522\n",
      "SubGD iter. 355/499: loss=4.424631552997125, w0=73.24071999999998, w1=13.523167851474966\n",
      "SubGD iter. 356/499: loss=4.424631554048455, w0=73.24085999999998, w1=13.52339076110083\n",
      "SubGD iter. 357/499: loss=4.42463156220527, w0=73.24085999999998, w1=13.523356613952274\n",
      "SubGD iter. 358/499: loss=4.424631560539515, w0=73.24085999999998, w1=13.523322466803718\n",
      "SubGD iter. 359/499: loss=4.424631558873761, w0=73.24085999999998, w1=13.523288319655162\n",
      "SubGD iter. 360/499: loss=4.424631557208007, w0=73.24085999999998, w1=13.523254172506606\n",
      "SubGD iter. 361/499: loss=4.424631555542253, w0=73.24085999999998, w1=13.52322002535805\n",
      "SubGD iter. 362/499: loss=4.424631553876499, w0=73.24085999999998, w1=13.523185878209494\n",
      "SubGD iter. 363/499: loss=4.4246315522107444, w0=73.24085999999998, w1=13.523151731060938\n",
      "SubGD iter. 364/499: loss=4.424631550544991, w0=73.24085999999998, w1=13.523117583912382\n",
      "SubGD iter. 365/499: loss=4.424631548879238, w0=73.24085999999998, w1=13.523083436763827\n",
      "SubGD iter. 366/499: loss=4.424631552929672, w0=73.24099999999999, w1=13.52330634638969\n",
      "SubGD iter. 367/499: loss=4.4246315580873805, w0=73.24099999999999, w1=13.523272199241134\n",
      "SubGD iter. 368/499: loss=4.424631556421627, w0=73.24099999999999, w1=13.523238052092578\n",
      "SubGD iter. 369/499: loss=4.424631554755873, w0=73.24099999999999, w1=13.523203904944022\n",
      "SubGD iter. 370/499: loss=4.424631553090119, w0=73.24099999999999, w1=13.523169757795467\n",
      "SubGD iter. 371/499: loss=4.4246315514243655, w0=73.24099999999999, w1=13.52313561064691\n",
      "SubGD iter. 372/499: loss=4.424631549758611, w0=73.24099999999999, w1=13.523101463498355\n",
      "SubGD iter. 373/499: loss=4.424631548092857, w0=73.24099999999999, w1=13.523067316349799\n",
      "SubGD iter. 374/499: loss=4.424631546427102, w0=73.24099999999999, w1=13.523033169201243\n",
      "SubGD iter. 375/499: loss=4.424631544761348, w0=73.24099999999999, w1=13.522999022052687\n",
      "SubGD iter. 376/499: loss=4.424631551810888, w0=73.24113999999999, w1=13.52322193167855\n",
      "SubGD iter. 377/499: loss=4.424631553969492, w0=73.24113999999999, w1=13.523187784529995\n",
      "SubGD iter. 378/499: loss=4.4246315523037385, w0=73.24113999999999, w1=13.523153637381439\n",
      "SubGD iter. 379/499: loss=4.424631550637985, w0=73.24113999999999, w1=13.523119490232883\n",
      "SubGD iter. 380/499: loss=4.424631548972231, w0=73.24113999999999, w1=13.523085343084327\n",
      "SubGD iter. 381/499: loss=4.4246315473064755, w0=73.24113999999999, w1=13.523051195935771\n",
      "SubGD iter. 382/499: loss=4.4246315456407235, w0=73.24113999999999, w1=13.523017048787215\n",
      "SubGD iter. 383/499: loss=4.424631543974968, w0=73.24113999999999, w1=13.52298290163866\n",
      "SubGD iter. 384/499: loss=4.424631542309214, w0=73.24113999999999, w1=13.522948754490104\n",
      "SubGD iter. 385/499: loss=4.424631540643461, w0=73.24113999999999, w1=13.522914607341548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 386/499: loss=4.424631550692105, w0=73.24127999999999, w1=13.523137516967411\n",
      "SubGD iter. 387/499: loss=4.424631549851604, w0=73.24127999999999, w1=13.523103369818855\n",
      "SubGD iter. 388/499: loss=4.42463154818585, w0=73.24127999999999, w1=13.5230692226703\n",
      "SubGD iter. 389/499: loss=4.4246315465200965, w0=73.24127999999999, w1=13.523035075521744\n",
      "SubGD iter. 390/499: loss=4.424631544854342, w0=73.24127999999999, w1=13.523000928373188\n",
      "SubGD iter. 391/499: loss=4.424631543188589, w0=73.24127999999999, w1=13.522966781224632\n",
      "SubGD iter. 392/499: loss=4.424631541522834, w0=73.24127999999999, w1=13.522932634076076\n",
      "SubGD iter. 393/499: loss=4.424631539857081, w0=73.24127999999999, w1=13.52289848692752\n",
      "SubGD iter. 394/499: loss=4.424631538191327, w0=73.24127999999999, w1=13.522864339778964\n",
      "SubGD iter. 395/499: loss=4.4246315386994235, w0=73.24141999999999, w1=13.523087249404828\n",
      "SubGD iter. 396/499: loss=4.4246315473994695, w0=73.24141999999999, w1=13.523053102256272\n",
      "SubGD iter. 397/499: loss=4.424631545733717, w0=73.24141999999999, w1=13.523018955107716\n",
      "SubGD iter. 398/499: loss=4.424631544067962, w0=73.24141999999999, w1=13.52298480795916\n",
      "SubGD iter. 399/499: loss=4.424631542402208, w0=73.24141999999999, w1=13.522950660810604\n",
      "SubGD iter. 400/499: loss=4.4246315407364545, w0=73.24141999999999, w1=13.522916513662048\n",
      "SubGD iter. 401/499: loss=4.424631539070701, w0=73.24141999999999, w1=13.522882366513493\n",
      "SubGD iter. 402/499: loss=4.424631537404947, w0=73.24141999999999, w1=13.522848219364937\n",
      "SubGD iter. 403/499: loss=4.424631535739192, w0=73.24141999999999, w1=13.52281407221638\n",
      "SubGD iter. 404/499: loss=4.424631534073439, w0=73.24141999999999, w1=13.522779925067825\n",
      "SubGD iter. 405/499: loss=4.424631537580641, w0=73.24155999999999, w1=13.523002834693688\n",
      "SubGD iter. 406/499: loss=4.424631543281581, w0=73.24155999999999, w1=13.522968687545132\n",
      "SubGD iter. 407/499: loss=4.4246315416158275, w0=73.24155999999999, w1=13.522934540396577\n",
      "SubGD iter. 408/499: loss=4.424631539950075, w0=73.24155999999999, w1=13.52290039324802\n",
      "SubGD iter. 409/499: loss=4.42463153828432, w0=73.24155999999999, w1=13.522866246099465\n",
      "SubGD iter. 410/499: loss=4.424631536618566, w0=73.24155999999999, w1=13.522832098950909\n",
      "SubGD iter. 411/499: loss=4.4246315349528125, w0=73.24155999999999, w1=13.522797951802353\n",
      "SubGD iter. 412/499: loss=4.424631533287058, w0=73.24155999999999, w1=13.522763804653797\n",
      "SubGD iter. 413/499: loss=4.424631531621305, w0=73.24155999999999, w1=13.522729657505241\n",
      "SubGD iter. 414/499: loss=4.42463152995555, w0=73.24155999999999, w1=13.522695510356685\n",
      "SubGD iter. 415/499: loss=4.424631536461858, w0=73.2417, w1=13.522918419982549\n",
      "SubGD iter. 416/499: loss=4.4246315403358025, w0=73.24155999999999, w1=13.522905630681082\n",
      "SubGD iter. 417/499: loss=4.424631538539811, w0=73.24155999999999, w1=13.522871483532526\n",
      "SubGD iter. 418/499: loss=4.424631536874056, w0=73.24155999999999, w1=13.52283733638397\n",
      "SubGD iter. 419/499: loss=4.424631535208303, w0=73.24155999999999, w1=13.522803189235415\n",
      "SubGD iter. 420/499: loss=4.424631533542549, w0=73.24155999999999, w1=13.522769042086859\n",
      "SubGD iter. 421/499: loss=4.424631531876795, w0=73.24155999999999, w1=13.522734894938303\n",
      "SubGD iter. 422/499: loss=4.424631530211041, w0=73.24155999999999, w1=13.522700747789747\n",
      "SubGD iter. 423/499: loss=4.424631534794037, w0=73.2417, w1=13.52292365741561\n",
      "SubGD iter. 424/499: loss=4.424631540431494, w0=73.24155999999999, w1=13.522910868114144\n",
      "SubGD iter. 425/499: loss=4.4246315387953015, w0=73.24155999999999, w1=13.522876720965588\n",
      "SubGD iter. 426/499: loss=4.424631537129547, w0=73.24155999999999, w1=13.522842573817032\n",
      "SubGD iter. 427/499: loss=4.424631535463794, w0=73.24155999999999, w1=13.522808426668476\n",
      "SubGD iter. 428/499: loss=4.424631533798039, w0=73.24155999999999, w1=13.52277427951992\n",
      "SubGD iter. 429/499: loss=4.424631532132286, w0=73.24155999999999, w1=13.522740132371364\n",
      "SubGD iter. 430/499: loss=4.424631530466532, w0=73.24155999999999, w1=13.522705985222808\n",
      "SubGD iter. 431/499: loss=4.424631533126217, w0=73.2417, w1=13.522928894848672\n",
      "SubGD iter. 432/499: loss=4.424631540527184, w0=73.24155999999999, w1=13.522916105547205\n",
      "SubGD iter. 433/499: loss=4.424631539050792, w0=73.24155999999999, w1=13.52288195839865\n",
      "SubGD iter. 434/499: loss=4.424631537385038, w0=73.24155999999999, w1=13.522847811250093\n",
      "SubGD iter. 435/499: loss=4.424631535719284, w0=73.24155999999999, w1=13.522813664101538\n",
      "SubGD iter. 436/499: loss=4.42463153405353, w0=73.24155999999999, w1=13.522779516952982\n",
      "SubGD iter. 437/499: loss=4.424631532387776, w0=73.24155999999999, w1=13.522745369804426\n",
      "SubGD iter. 438/499: loss=4.424631530722022, w0=73.24155999999999, w1=13.52271122265587\n",
      "SubGD iter. 439/499: loss=4.424631531458396, w0=73.2417, w1=13.522934132281733\n",
      "SubGD iter. 440/499: loss=4.424631540622874, w0=73.24155999999999, w1=13.522921342980267\n",
      "SubGD iter. 441/499: loss=4.424631539306283, w0=73.24155999999999, w1=13.52288719583171\n",
      "SubGD iter. 442/499: loss=4.424631537640528, w0=73.24155999999999, w1=13.522853048683155\n",
      "SubGD iter. 443/499: loss=4.4246315359747745, w0=73.24155999999999, w1=13.522818901534599\n",
      "SubGD iter. 444/499: loss=4.424631534309021, w0=73.24155999999999, w1=13.522784754386043\n",
      "SubGD iter. 445/499: loss=4.424631532643267, w0=73.24155999999999, w1=13.522750607237487\n",
      "SubGD iter. 446/499: loss=4.424631530977512, w0=73.24155999999999, w1=13.522716460088931\n",
      "SubGD iter. 447/499: loss=4.4246315297905765, w0=73.2417, w1=13.522939369714795\n",
      "SubGD iter. 448/499: loss=4.424631540718565, w0=73.24155999999999, w1=13.522926580413328\n",
      "SubGD iter. 449/499: loss=4.424631539561774, w0=73.24155999999999, w1=13.522892433264772\n",
      "SubGD iter. 450/499: loss=4.424631537896019, w0=73.24155999999999, w1=13.522858286116216\n",
      "SubGD iter. 451/499: loss=4.424631536230265, w0=73.24155999999999, w1=13.52282413896766\n",
      "SubGD iter. 452/499: loss=4.4246315345645115, w0=73.24155999999999, w1=13.522789991819105\n",
      "SubGD iter. 453/499: loss=4.424631532898758, w0=73.24155999999999, w1=13.522755844670549\n",
      "SubGD iter. 454/499: loss=4.424631531233003, w0=73.24155999999999, w1=13.522721697521993\n",
      "SubGD iter. 455/499: loss=4.424631529567249, w0=73.24155999999999, w1=13.522687550373437\n",
      "SubGD iter. 456/499: loss=4.424631538996652, w0=73.2417, w1=13.5229104599993\n",
      "SubGD iter. 457/499: loss=4.424631540190371, w0=73.24155999999999, w1=13.522897670697834\n",
      "SubGD iter. 458/499: loss=4.42463153815151, w0=73.24155999999999, w1=13.522863523549278\n",
      "SubGD iter. 459/499: loss=4.424631536485755, w0=73.24155999999999, w1=13.522829376400722\n",
      "SubGD iter. 460/499: loss=4.424631534820002, w0=73.24155999999999, w1=13.522795229252166\n",
      "SubGD iter. 461/499: loss=4.4246315331542485, w0=73.24155999999999, w1=13.52276108210361\n",
      "SubGD iter. 462/499: loss=4.424631531488494, w0=73.24155999999999, w1=13.522726934955054\n",
      "SubGD iter. 463/499: loss=4.42463152982274, w0=73.24155999999999, w1=13.522692787806498\n",
      "SubGD iter. 464/499: loss=4.424631537328833, w0=73.2417, w1=13.522915697432362\n",
      "SubGD iter. 465/499: loss=4.424631540286062, w0=73.24155999999999, w1=13.522902908130895\n",
      "SubGD iter. 466/499: loss=4.4246315384070005, w0=73.24155999999999, w1=13.52286876098234\n",
      "SubGD iter. 467/499: loss=4.424631536741246, w0=73.24155999999999, w1=13.522834613833783\n",
      "SubGD iter. 468/499: loss=4.424631535075493, w0=73.24155999999999, w1=13.522800466685228\n",
      "SubGD iter. 469/499: loss=4.424631533409738, w0=73.24155999999999, w1=13.522766319536672\n",
      "SubGD iter. 470/499: loss=4.424631531743984, w0=73.24155999999999, w1=13.522732172388116\n",
      "SubGD iter. 471/499: loss=4.424631530078232, w0=73.24155999999999, w1=13.52269802523956\n",
      "SubGD iter. 472/499: loss=4.424631535661012, w0=73.2417, w1=13.522920934865423\n",
      "SubGD iter. 473/499: loss=4.4246315403817515, w0=73.24155999999999, w1=13.522908145563957\n",
      "SubGD iter. 474/499: loss=4.424631538662491, w0=73.24155999999999, w1=13.5228739984154\n",
      "SubGD iter. 475/499: loss=4.4246315369967375, w0=73.24155999999999, w1=13.522839851266845\n",
      "SubGD iter. 476/499: loss=4.424631535330982, w0=73.24155999999999, w1=13.522805704118289\n",
      "SubGD iter. 477/499: loss=4.42463153366523, w0=73.24155999999999, w1=13.522771556969733\n",
      "SubGD iter. 478/499: loss=4.4246315319994745, w0=73.24155999999999, w1=13.522737409821177\n",
      "SubGD iter. 479/499: loss=4.424631530333721, w0=73.24155999999999, w1=13.522703262672621\n",
      "SubGD iter. 480/499: loss=4.424631533993192, w0=73.2417, w1=13.522926172298485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 481/499: loss=4.424631540477442, w0=73.24155999999999, w1=13.522913382997018\n",
      "SubGD iter. 482/499: loss=4.424631538917981, w0=73.24155999999999, w1=13.522879235848462\n",
      "SubGD iter. 483/499: loss=4.424631537252228, w0=73.24155999999999, w1=13.522845088699906\n",
      "SubGD iter. 484/499: loss=4.424631535586474, w0=73.24155999999999, w1=13.52281094155135\n",
      "SubGD iter. 485/499: loss=4.42463153392072, w0=73.24155999999999, w1=13.522776794402795\n",
      "SubGD iter. 486/499: loss=4.424631532254966, w0=73.24155999999999, w1=13.522742647254239\n",
      "SubGD iter. 487/499: loss=4.424631530589211, w0=73.24155999999999, w1=13.522708500105683\n",
      "SubGD iter. 488/499: loss=4.424631532325371, w0=73.2417, w1=13.522931409731546\n",
      "SubGD iter. 489/499: loss=4.424631540573133, w0=73.24155999999999, w1=13.52291862043008\n",
      "SubGD iter. 490/499: loss=4.424631539173472, w0=73.24155999999999, w1=13.522884473281524\n",
      "SubGD iter. 491/499: loss=4.424631537507717, w0=73.24155999999999, w1=13.522850326132968\n",
      "SubGD iter. 492/499: loss=4.424631535841964, w0=73.24155999999999, w1=13.522816178984412\n",
      "SubGD iter. 493/499: loss=4.424631534176211, w0=73.24155999999999, w1=13.522782031835856\n",
      "SubGD iter. 494/499: loss=4.424631532510456, w0=73.24155999999999, w1=13.5227478846873\n",
      "SubGD iter. 495/499: loss=4.424631530844702, w0=73.24155999999999, w1=13.522713737538744\n",
      "SubGD iter. 496/499: loss=4.424631530657551, w0=73.2417, w1=13.522936647164608\n",
      "SubGD iter. 497/499: loss=4.424631540668822, w0=73.24155999999999, w1=13.522923857863141\n",
      "SubGD iter. 498/499: loss=4.424631539428963, w0=73.24155999999999, w1=13.522889710714585\n",
      "SubGD iter. 499/499: loss=4.424631537763208, w0=73.24155999999999, w1=13.52285556356603\n",
      "SubGD: execution time=14.254 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addee1c656624cef91fff6c566b00e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "        for sgd_y, sgd_tx in batch_iter(y, tx, batch_size):\n",
    "            gradient=compute_subgradient_mae(sgd_y, sgd_tx, w)\n",
    "            loss=compute_subgradient_loss(sgd_y, sgd_tx,w)\n",
    "            w=w-gamma*gradient\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=91.16177193214804, w0=0.7, w1=0.6415810456366805\n",
      "SubSGD iter. 1/499: loss=62.94242296747063, w0=1.4, w1=0.2173140433934982\n",
      "SubSGD iter. 2/499: loss=77.32817166197381, w0=2.0999999999999996, w1=0.4935212594326231\n",
      "SubSGD iter. 3/499: loss=77.84876964276872, w0=2.8, w1=0.8855179270064097\n",
      "SubSGD iter. 4/499: loss=58.27318120407499, w0=3.5, w1=0.18180972415787544\n",
      "SubSGD iter. 5/499: loss=73.185644693066, w0=4.2, w1=0.12042473302751833\n",
      "SubSGD iter. 6/499: loss=48.1817815648039, w0=4.9, w1=-0.801582168809935\n",
      "SubSGD iter. 7/499: loss=83.0882878969828, w0=5.6000000000000005, w1=-0.11741277955418761\n",
      "SubSGD iter. 8/499: loss=78.5673112858047, w0=6.300000000000001, w1=-0.3264636599988791\n",
      "SubSGD iter. 9/499: loss=60.01715478383878, w0=7.000000000000001, w1=-0.6559937584391224\n",
      "SubSGD iter. 10/499: loss=37.80714567637469, w0=7.700000000000001, w1=-2.1398196741021307\n",
      "SubSGD iter. 11/499: loss=66.37122471353136, w0=8.4, w1=-2.0825649598221245\n",
      "SubSGD iter. 12/499: loss=39.20376967461181, w0=9.1, w1=-3.3584887887544803\n",
      "SubSGD iter. 13/499: loss=96.39639160741433, w0=9.799999999999999, w1=-2.062383648524965\n",
      "SubSGD iter. 14/499: loss=82.40501619044748, w0=10.499999999999998, w1=-1.3855164481010385\n",
      "SubSGD iter. 15/499: loss=85.91026175309226, w0=11.199999999999998, w1=-0.4993744170220774\n",
      "SubSGD iter. 16/499: loss=80.84523950129687, w0=11.899999999999997, w1=0.22675755965740496\n",
      "SubSGD iter. 17/499: loss=79.13131400811957, w0=12.599999999999996, w1=1.484624476929557\n",
      "SubSGD iter. 18/499: loss=85.95951083801152, w0=13.299999999999995, w1=2.848901433558839\n",
      "SubSGD iter. 19/499: loss=72.5235154126594, w0=13.999999999999995, w1=3.8573568033701315\n",
      "SubSGD iter. 20/499: loss=66.11664432068085, w0=14.699999999999994, w1=4.584738868641437\n",
      "SubSGD iter. 21/499: loss=53.864577081258744, w0=15.399999999999993, w1=4.35940222301589\n",
      "SubSGD iter. 22/499: loss=54.37165690967745, w0=16.099999999999994, w1=4.337101553548669\n",
      "SubSGD iter. 23/499: loss=59.74735557044981, w0=16.799999999999994, w1=4.744753733694935\n",
      "SubSGD iter. 24/499: loss=66.37836755954442, w0=17.499999999999993, w1=5.530513436596843\n",
      "SubSGD iter. 25/499: loss=63.97896758325085, w0=18.199999999999992, w1=5.879228092609968\n",
      "SubSGD iter. 26/499: loss=66.0058532365197, w0=18.89999999999999, w1=6.618087392994429\n",
      "SubSGD iter. 27/499: loss=55.970284234393546, w0=19.59999999999999, w1=6.847402390947953\n",
      "SubSGD iter. 28/499: loss=37.73266285892677, w0=20.29999999999999, w1=6.000174668960012\n",
      "SubSGD iter. 29/499: loss=43.3053624940044, w0=20.99999999999999, w1=5.28936511561472\n",
      "SubSGD iter. 30/499: loss=56.946133683643595, w0=21.69999999999999, w1=5.558843504116987\n",
      "SubSGD iter. 31/499: loss=54.24627905951769, w0=22.399999999999988, w1=5.868917630056087\n",
      "SubSGD iter. 32/499: loss=37.39275904311471, w0=23.099999999999987, w1=4.890464397187754\n",
      "SubSGD iter. 33/499: loss=56.84617808094608, w0=23.799999999999986, w1=5.50334796808118\n",
      "SubSGD iter. 34/499: loss=48.10878248644305, w0=24.499999999999986, w1=5.468875255955819\n",
      "SubSGD iter. 35/499: loss=49.934582863905234, w0=25.199999999999985, w1=5.4505892790986366\n",
      "SubSGD iter. 36/499: loss=37.84729028615803, w0=25.899999999999984, w1=4.739779725753344\n",
      "SubSGD iter. 37/499: loss=29.429173933244726, w0=26.599999999999984, w1=3.5378224762584933\n",
      "SubSGD iter. 38/499: loss=28.482447549113104, w0=27.299999999999983, w1=2.230403444678487\n",
      "SubSGD iter. 39/499: loss=49.25246941919504, w0=27.999999999999982, w1=2.7581036312925225\n",
      "SubSGD iter. 40/499: loss=42.64185068242796, w0=28.69999999999998, w1=1.798018827662849\n",
      "SubSGD iter. 41/499: loss=54.00537956598309, w0=29.39999999999998, w1=1.9379701210269185\n",
      "SubSGD iter. 42/499: loss=50.65511154934142, w0=30.09999999999998, w1=2.0196076306556656\n",
      "SubSGD iter. 43/499: loss=33.5177491695405, w0=30.79999999999998, w1=1.6047060390391952\n",
      "SubSGD iter. 44/499: loss=31.45901555663312, w0=31.49999999999998, w1=1.114716537584814\n",
      "SubSGD iter. 45/499: loss=57.69620629714429, w0=32.19999999999998, w1=1.940048533771606\n",
      "SubSGD iter. 46/499: loss=50.18082571853372, w0=32.899999999999984, w1=2.0687982688719364\n",
      "SubSGD iter. 47/499: loss=36.41056280806572, w0=33.59999999999999, w1=1.8302425587218643\n",
      "SubSGD iter. 48/499: loss=28.99408865708154, w0=34.29999999999999, w1=1.784672896123889\n",
      "SubSGD iter. 49/499: loss=32.90805553433601, w0=34.99999999999999, w1=1.4037701750521776\n",
      "SubSGD iter. 50/499: loss=57.56400838092082, w0=35.699999999999996, w1=2.3106962323709395\n",
      "SubSGD iter. 51/499: loss=61.726866790954126, w0=36.4, w1=3.1139190583405343\n",
      "SubSGD iter. 52/499: loss=23.07715054564399, w0=37.1, w1=2.3767165957158873\n",
      "SubSGD iter. 53/499: loss=21.61012560625103, w0=37.800000000000004, w1=2.2058621291961447\n",
      "SubSGD iter. 54/499: loss=41.343321712634406, w0=38.50000000000001, w1=2.3090409362131585\n",
      "SubSGD iter. 55/499: loss=41.218541186187345, w0=39.20000000000001, w1=2.3790639200160744\n",
      "SubSGD iter. 56/499: loss=21.33352442945163, w0=39.90000000000001, w1=1.1095890703576379\n",
      "SubSGD iter. 57/499: loss=18.366838656074563, w0=40.600000000000016, w1=1.0712452853507786\n",
      "SubSGD iter. 58/499: loss=18.58078386603797, w0=41.30000000000002, w1=-0.01163383933338169\n",
      "SubSGD iter. 59/499: loss=53.66070908814515, w0=42.00000000000002, w1=0.9760039633360466\n",
      "SubSGD iter. 60/499: loss=39.30570478833787, w0=42.700000000000024, w1=1.294504019953059\n",
      "SubSGD iter. 61/499: loss=42.289517685064816, w0=43.40000000000003, w1=1.9599017090394755\n",
      "SubSGD iter. 62/499: loss=28.28434346428869, w0=44.10000000000003, w1=1.3379060561498735\n",
      "SubSGD iter. 63/499: loss=26.15740808136436, w0=44.80000000000003, w1=1.324777825261894\n",
      "SubSGD iter. 64/499: loss=20.83362504695816, w0=45.500000000000036, w1=1.2102212989255807\n",
      "SubSGD iter. 65/499: loss=6.1883205392309435, w0=46.20000000000004, w1=-0.0572916145295288\n",
      "SubSGD iter. 66/499: loss=14.777481146353033, w0=46.90000000000004, w1=-0.5184461804441176\n",
      "SubSGD iter. 67/499: loss=28.186610540084402, w0=47.600000000000044, w1=-0.6126497682004798\n",
      "SubSGD iter. 68/499: loss=7.432657332712665, w0=48.30000000000005, w1=-1.0815253502050546\n",
      "SubSGD iter. 69/499: loss=3.841076268223368, w0=49.00000000000005, w1=-1.6438417799901996\n",
      "SubSGD iter. 70/499: loss=40.69533104258656, w0=49.70000000000005, w1=-0.8370342738956467\n",
      "SubSGD iter. 71/499: loss=23.57893848990132, w0=50.400000000000055, w1=-0.8940912330447432\n",
      "SubSGD iter. 72/499: loss=35.00002231103798, w0=51.10000000000006, w1=-0.7746116376961655\n",
      "SubSGD iter. 73/499: loss=13.658096187621886, w0=51.80000000000006, w1=-0.8633587663871354\n",
      "SubSGD iter. 74/499: loss=13.33781559282096, w0=52.500000000000064, w1=-1.342729165706399\n",
      "SubSGD iter. 75/499: loss=39.1378331775055, w0=53.20000000000007, w1=-0.6074587436795054\n",
      "SubSGD iter. 76/499: loss=4.17880551881602, w0=52.500000000000064, w1=0.5042317352691059\n",
      "SubSGD iter. 77/499: loss=19.470131335257406, w0=53.20000000000007, w1=0.6888895435409729\n",
      "SubSGD iter. 78/499: loss=22.250976099783976, w0=53.90000000000007, w1=1.1632962323300053\n",
      "SubSGD iter. 79/499: loss=16.782650879479554, w0=54.60000000000007, w1=1.1578557164283247\n",
      "SubSGD iter. 80/499: loss=0.7759318444425318, w0=55.300000000000075, w1=0.5832806355344334\n",
      "SubSGD iter. 81/499: loss=2.492668015222108, w0=54.60000000000007, w1=1.6010068767566352\n",
      "SubSGD iter. 82/499: loss=13.735063596875783, w0=55.300000000000075, w1=1.3660091957828118\n",
      "SubSGD iter. 83/499: loss=27.625996853582947, w0=56.00000000000008, w1=1.3128773477696971\n",
      "SubSGD iter. 84/499: loss=8.375564544175191, w0=55.300000000000075, w1=2.129697671297874\n",
      "SubSGD iter. 85/499: loss=2.5457691748628903, w0=54.60000000000007, w1=2.8906494364269926\n",
      "SubSGD iter. 86/499: loss=6.515810414785456, w0=55.300000000000075, w1=2.3733150894230857\n",
      "SubSGD iter. 87/499: loss=16.933475412298563, w0=56.00000000000008, w1=2.670227634193243\n",
      "SubSGD iter. 88/499: loss=3.7170096841235036, w0=56.70000000000008, w1=2.7260481301585857\n",
      "SubSGD iter. 89/499: loss=11.10674968758837, w0=57.400000000000084, w1=2.574261812253678\n",
      "SubSGD iter. 90/499: loss=16.537358506020816, w0=58.10000000000009, w1=2.736550877311938\n",
      "SubSGD iter. 91/499: loss=11.438128804795568, w0=58.80000000000009, w1=2.497995167161866\n",
      "SubSGD iter. 92/499: loss=10.411976926111329, w0=59.50000000000009, w1=1.7064312731795712\n",
      "SubSGD iter. 93/499: loss=2.82242276487235, w0=60.200000000000095, w1=1.3073768137656843\n",
      "SubSGD iter. 94/499: loss=11.368840289147279, w0=60.9000000000001, w1=1.122067935677919\n",
      "SubSGD iter. 95/499: loss=10.990172539898637, w0=61.6000000000001, w1=0.8503379580207536\n",
      "SubSGD iter. 96/499: loss=24.693920424570294, w0=62.300000000000104, w1=1.5648788244244622\n",
      "SubSGD iter. 97/499: loss=13.286207824919828, w0=61.6000000000001, w1=3.0804988884464093\n",
      "SubSGD iter. 98/499: loss=0.37420216107170745, w0=60.9000000000001, w1=4.179450328880066\n",
      "SubSGD iter. 99/499: loss=6.452377211607391, w0=61.6000000000001, w1=3.5301803254472617\n",
      "SubSGD iter. 100/499: loss=27.852782835207037, w0=62.300000000000104, w1=4.340431388212985\n",
      "SubSGD iter. 101/499: loss=2.170735035401684, w0=63.00000000000011, w1=4.013008380022366\n",
      "SubSGD iter. 102/499: loss=1.69939552465938, w0=63.70000000000011, w1=3.5254787575827717\n",
      "SubSGD iter. 103/499: loss=4.7643225769313275, w0=64.4000000000001, w1=3.3054229759354414\n",
      "SubSGD iter. 104/499: loss=6.294575287278796, w0=63.7000000000001, w1=4.266675941850373\n",
      "SubSGD iter. 105/499: loss=11.281113158198195, w0=64.4000000000001, w1=4.576459477793435\n",
      "SubSGD iter. 106/499: loss=0.26610165511953454, w0=65.10000000000011, w1=4.054190070906466\n",
      "SubSGD iter. 107/499: loss=20.021266543995836, w0=65.80000000000011, w1=5.506368328504954\n",
      "SubSGD iter. 108/499: loss=7.1432436765338, w0=66.50000000000011, w1=5.859194923371775\n",
      "SubSGD iter. 109/499: loss=13.138317763748006, w0=67.20000000000012, w1=6.509462045141306\n",
      "SubSGD iter. 110/499: loss=0.5014314340326962, w0=67.90000000000012, w1=5.707344209842749\n",
      "SubSGD iter. 111/499: loss=3.975230261620254, w0=68.60000000000012, w1=5.020905404124567\n",
      "SubSGD iter. 112/499: loss=18.786790660461364, w0=69.30000000000013, w1=6.692242444727327\n",
      "SubSGD iter. 113/499: loss=15.12107685337834, w0=70.00000000000013, w1=7.717628516354896\n",
      "SubSGD iter. 114/499: loss=12.494517533622016, w0=70.70000000000013, w1=9.176902478733291\n",
      "SubSGD iter. 115/499: loss=8.161355001474703, w0=70.00000000000013, w1=9.854357704201743\n",
      "SubSGD iter. 116/499: loss=9.674511663108348, w0=70.70000000000013, w1=10.977998424960463\n",
      "SubSGD iter. 117/499: loss=0.8970275854632916, w0=70.00000000000013, w1=10.317970352611782\n",
      "SubSGD iter. 118/499: loss=13.478686731126302, w0=69.30000000000013, w1=11.471788756377949\n",
      "SubSGD iter. 119/499: loss=10.47678706568535, w0=70.00000000000013, w1=10.35792162055821\n",
      "SubSGD iter. 120/499: loss=3.0433503735871668, w0=70.70000000000013, w1=9.91290888662504\n",
      "SubSGD iter. 121/499: loss=16.591419830965194, w0=71.40000000000013, w1=10.609638424746095\n",
      "SubSGD iter. 122/499: loss=12.656216263892873, w0=72.10000000000014, w1=12.628855636548248\n",
      "SubSGD iter. 123/499: loss=1.4836711591492104, w0=71.40000000000013, w1=13.188758745931732\n",
      "SubSGD iter. 124/499: loss=0.4141993775710233, w0=72.10000000000014, w1=12.056466246121701\n",
      "SubSGD iter. 125/499: loss=2.0956837652175864, w0=72.80000000000014, w1=13.43224819453801\n",
      "SubSGD iter. 126/499: loss=6.847126680159022, w0=73.50000000000014, w1=14.040738015791305\n",
      "SubSGD iter. 127/499: loss=0.5985749301910914, w0=74.20000000000014, w1=14.586690651286718\n",
      "SubSGD iter. 128/499: loss=6.868476403196716, w0=73.50000000000014, w1=15.401254423585762\n",
      "SubSGD iter. 129/499: loss=5.585768332641059, w0=72.80000000000014, w1=15.898276798872448\n",
      "SubSGD iter. 130/499: loss=9.415247683737476, w0=73.50000000000014, w1=14.940640531329242\n",
      "SubSGD iter. 131/499: loss=6.148143153054136, w0=72.80000000000014, w1=14.657340140883289\n",
      "SubSGD iter. 132/499: loss=2.0449017908773612, w0=72.10000000000014, w1=14.690457900104276\n",
      "SubSGD iter. 133/499: loss=3.0938356721937623, w0=71.40000000000013, w1=13.699514780908068\n",
      "SubSGD iter. 134/499: loss=9.491580303127087, w0=72.10000000000014, w1=12.025316264095377\n",
      "SubSGD iter. 135/499: loss=9.75514923192867, w0=72.80000000000014, w1=12.397615971115284\n",
      "SubSGD iter. 136/499: loss=5.901594074312982, w0=72.10000000000014, w1=11.986597511143437\n",
      "SubSGD iter. 137/499: loss=3.022385167178385, w0=72.80000000000014, w1=12.792803954624882\n",
      "SubSGD iter. 138/499: loss=3.1644497236975297, w0=72.10000000000014, w1=12.425854177974415\n",
      "SubSGD iter. 139/499: loss=2.5790879256105086, w0=71.40000000000013, w1=13.25985541903387\n",
      "SubSGD iter. 140/499: loss=0.7929477132892799, w0=72.10000000000014, w1=13.604511337187404\n",
      "SubSGD iter. 141/499: loss=3.6203720728736997, w0=72.80000000000014, w1=12.945131047389982\n",
      "SubSGD iter. 142/499: loss=4.94049013127141, w0=72.10000000000014, w1=13.801926428085864\n",
      "SubSGD iter. 143/499: loss=1.933207392839435, w0=71.40000000000013, w1=14.052296370561617\n",
      "SubSGD iter. 144/499: loss=9.38406705949258, w0=72.10000000000014, w1=14.500070820268606\n",
      "SubSGD iter. 145/499: loss=15.899141413027792, w0=72.80000000000014, w1=14.617649498081715\n",
      "SubSGD iter. 146/499: loss=2.9879783568579725, w0=73.50000000000014, w1=13.425458803743288\n",
      "SubSGD iter. 147/499: loss=10.158359550903342, w0=74.20000000000014, w1=13.622311630872167\n",
      "SubSGD iter. 148/499: loss=6.6457529409548215, w0=73.50000000000014, w1=12.84486993157312\n",
      "SubSGD iter. 149/499: loss=0.35102722512035456, w0=72.80000000000014, w1=13.500566562472844\n",
      "SubSGD iter. 150/499: loss=10.17831689551057, w0=73.50000000000014, w1=12.97758342180493\n",
      "SubSGD iter. 151/499: loss=8.84478572030251, w0=74.20000000000014, w1=12.76282773454163\n",
      "SubSGD iter. 152/499: loss=1.9672020322761625, w0=73.50000000000014, w1=12.028480728257382\n",
      "SubSGD iter. 153/499: loss=3.769989743619888, w0=74.20000000000014, w1=11.999194633509871\n",
      "SubSGD iter. 154/499: loss=0.7140953478333358, w0=74.90000000000015, w1=10.274075604203716\n",
      "SubSGD iter. 155/499: loss=0.9182683611351763, w0=74.20000000000014, w1=10.496126706546875\n",
      "SubSGD iter. 156/499: loss=6.240985735192737, w0=73.50000000000014, w1=10.302753271498851\n",
      "SubSGD iter. 157/499: loss=7.889274012737346, w0=72.80000000000014, w1=10.926610743907682\n",
      "SubSGD iter. 158/499: loss=1.1677016938017246, w0=72.10000000000014, w1=11.54049191985474\n",
      "SubSGD iter. 159/499: loss=12.534136729397765, w0=71.40000000000013, w1=11.490797127289154\n",
      "SubSGD iter. 160/499: loss=3.2004754805024334, w0=72.10000000000014, w1=11.83001164686832\n",
      "SubSGD iter. 161/499: loss=4.817193539294109, w0=72.80000000000014, w1=12.296365156322588\n",
      "SubSGD iter. 162/499: loss=4.128516291175579, w0=72.10000000000014, w1=13.062092918409201\n",
      "SubSGD iter. 163/499: loss=7.75656851705876, w0=72.80000000000014, w1=12.345334130656353\n",
      "SubSGD iter. 164/499: loss=4.435316595003719, w0=73.50000000000014, w1=11.312956277518904\n",
      "SubSGD iter. 165/499: loss=7.616378292425196, w0=72.80000000000014, w1=11.988017197770812\n",
      "SubSGD iter. 166/499: loss=0.48840460991958423, w0=72.10000000000014, w1=11.834200862425057\n",
      "SubSGD iter. 167/499: loss=6.464633445929351, w0=72.80000000000014, w1=11.536186587592365\n",
      "SubSGD iter. 168/499: loss=1.7947200437740776, w0=72.10000000000014, w1=11.373480515859647\n",
      "SubSGD iter. 169/499: loss=6.714521262844443, w0=71.40000000000013, w1=11.400816685009394\n",
      "SubSGD iter. 170/499: loss=0.9644091815635463, w0=72.10000000000014, w1=10.169709244514879\n",
      "SubSGD iter. 171/499: loss=3.5228094666578755, w0=72.80000000000014, w1=9.008712315389648\n",
      "SubSGD iter. 172/499: loss=7.768521802847715, w0=73.50000000000014, w1=9.091185048007596\n",
      "SubSGD iter. 173/499: loss=3.297573218574783, w0=72.80000000000014, w1=8.25500474871554\n",
      "SubSGD iter. 174/499: loss=15.327613385932857, w0=72.10000000000014, w1=9.111531660601937\n",
      "SubSGD iter. 175/499: loss=6.004928273521031, w0=72.80000000000014, w1=8.46482880130505\n",
      "SubSGD iter. 176/499: loss=7.405903596905588, w0=72.10000000000014, w1=8.161282901265324\n",
      "SubSGD iter. 177/499: loss=2.8610558336642242, w0=72.80000000000014, w1=7.416747822936364\n",
      "SubSGD iter. 178/499: loss=4.201221507311388, w0=73.50000000000014, w1=8.341040493848777\n",
      "SubSGD iter. 179/499: loss=1.148885483038498, w0=74.20000000000014, w1=7.923463057991501\n",
      "SubSGD iter. 180/499: loss=5.144717229049952, w0=73.50000000000014, w1=9.011289878137816\n",
      "SubSGD iter. 181/499: loss=0.7783920985092294, w0=74.20000000000014, w1=9.792319433120579\n",
      "SubSGD iter. 182/499: loss=4.981004718444403, w0=73.50000000000014, w1=11.035710198762555\n",
      "SubSGD iter. 183/499: loss=0.8165269398440813, w0=72.80000000000014, w1=11.568938909578787\n",
      "SubSGD iter. 184/499: loss=1.6038904707620745, w0=73.50000000000014, w1=10.812670669711405\n",
      "SubSGD iter. 185/499: loss=5.422800944771353, w0=72.80000000000014, w1=11.706208180509563\n",
      "SubSGD iter. 186/499: loss=0.994241100188141, w0=72.10000000000014, w1=12.290999515481793\n",
      "SubSGD iter. 187/499: loss=4.6226501746425726, w0=72.80000000000014, w1=13.052923870866275\n",
      "SubSGD iter. 188/499: loss=0.15181559958331547, w0=72.10000000000014, w1=12.725737987788865\n",
      "SubSGD iter. 189/499: loss=2.768489017450122, w0=71.40000000000013, w1=13.681683468304449\n",
      "SubSGD iter. 190/499: loss=4.610191617836776, w0=72.10000000000014, w1=14.424057549639926\n",
      "SubSGD iter. 191/499: loss=11.25879555237465, w0=72.80000000000014, w1=14.321887799113757\n",
      "SubSGD iter. 192/499: loss=0.45112704747927523, w0=73.50000000000014, w1=14.43917362712275\n",
      "SubSGD iter. 193/499: loss=2.380980701354005, w0=74.20000000000014, w1=14.213859755750201\n",
      "SubSGD iter. 194/499: loss=3.751108619027818, w0=73.50000000000014, w1=13.229281027549586\n",
      "SubSGD iter. 195/499: loss=9.344450204844307, w0=74.20000000000014, w1=13.04139972454425\n",
      "SubSGD iter. 196/499: loss=3.431566759140395, w0=74.90000000000015, w1=13.462458636845357\n",
      "SubSGD iter. 197/499: loss=2.7480907368295817, w0=74.20000000000014, w1=13.877579964135746\n",
      "SubSGD iter. 198/499: loss=7.171196383402446, w0=73.50000000000014, w1=12.795519224684506\n",
      "SubSGD iter. 199/499: loss=4.368459361328412, w0=74.20000000000014, w1=11.688797300652427\n",
      "SubSGD iter. 200/499: loss=2.384363047151723, w0=74.90000000000015, w1=12.61731281607115\n",
      "SubSGD iter. 201/499: loss=1.6330054430071854, w0=74.20000000000014, w1=13.645256334662005\n",
      "SubSGD iter. 202/499: loss=7.159732577673104, w0=73.50000000000014, w1=14.770420652205019\n",
      "SubSGD iter. 203/499: loss=0.2666763105659271, w0=74.20000000000014, w1=13.883767526352978\n",
      "SubSGD iter. 204/499: loss=6.865858213321545, w0=73.50000000000014, w1=13.987296531757028\n",
      "SubSGD iter. 205/499: loss=5.461177555841225, w0=72.80000000000014, w1=14.826943726536223\n",
      "SubSGD iter. 206/499: loss=11.973868515888896, w0=72.10000000000014, w1=14.051673282180795\n",
      "SubSGD iter. 207/499: loss=5.785925530204096, w0=72.80000000000014, w1=14.130579018028598\n",
      "SubSGD iter. 208/499: loss=0.3533496555008213, w0=72.10000000000014, w1=13.571429498116823\n",
      "SubSGD iter. 209/499: loss=0.6586201707099733, w0=72.80000000000014, w1=12.495186351138033\n",
      "SubSGD iter. 210/499: loss=3.796018146501943, w0=72.10000000000014, w1=13.093203709193094\n",
      "SubSGD iter. 211/499: loss=8.090760023847025, w0=72.80000000000014, w1=13.728510930440674\n",
      "SubSGD iter. 212/499: loss=1.1022083176435586, w0=72.10000000000014, w1=14.550566303167555\n",
      "SubSGD iter. 213/499: loss=4.744792239717313, w0=72.80000000000014, w1=15.754246756485033\n",
      "SubSGD iter. 214/499: loss=12.492173773092603, w0=73.50000000000014, w1=15.675072638924654\n",
      "SubSGD iter. 215/499: loss=2.6989384947403536, w0=72.80000000000014, w1=16.424085517960144\n",
      "SubSGD iter. 216/499: loss=5.589078391317329, w0=72.10000000000014, w1=15.20364366322702\n",
      "SubSGD iter. 217/499: loss=8.768435580821091, w0=72.80000000000014, w1=15.49493718538233\n",
      "SubSGD iter. 218/499: loss=6.544734464028139, w0=72.10000000000014, w1=15.555441383424826\n",
      "SubSGD iter. 219/499: loss=8.20615197472236, w0=71.40000000000013, w1=14.298094212106287\n",
      "SubSGD iter. 220/499: loss=3.08700041064116, w0=70.70000000000013, w1=14.826630863241759\n",
      "SubSGD iter. 221/499: loss=4.709248571310297, w0=71.40000000000013, w1=15.322065245300546\n",
      "SubSGD iter. 222/499: loss=1.8013840871220594, w0=72.10000000000014, w1=15.266044931759557\n",
      "SubSGD iter. 223/499: loss=1.7093021411130707, w0=72.80000000000014, w1=14.993561998964452\n",
      "SubSGD iter. 224/499: loss=1.7172054665636765, w0=72.10000000000014, w1=16.048661283768308\n",
      "SubSGD iter. 225/499: loss=1.5186412690098905, w0=71.40000000000013, w1=16.059761677782227\n",
      "SubSGD iter. 226/499: loss=2.1701516342637603, w0=72.10000000000014, w1=15.082190451627223\n",
      "SubSGD iter. 227/499: loss=4.216892123837177, w0=72.80000000000014, w1=14.322810925702788\n",
      "SubSGD iter. 228/499: loss=4.812720296230225, w0=72.10000000000014, w1=14.987617778903113\n",
      "SubSGD iter. 229/499: loss=3.3701270978828646, w0=72.80000000000014, w1=14.548407279579857\n",
      "SubSGD iter. 230/499: loss=5.147885783755591, w0=72.10000000000014, w1=15.083625000435045\n",
      "SubSGD iter. 231/499: loss=5.958218901110385, w0=71.40000000000013, w1=15.914869548342432\n",
      "SubSGD iter. 232/499: loss=9.596947315803412, w0=70.70000000000013, w1=15.884416355732096\n",
      "SubSGD iter. 233/499: loss=0.5767898900559629, w0=70.00000000000013, w1=16.555661651040968\n",
      "SubSGD iter. 234/499: loss=17.68466768221097, w0=70.70000000000013, w1=16.564550422903928\n",
      "SubSGD iter. 235/499: loss=2.411423326990146, w0=71.40000000000013, w1=16.90780343634439\n",
      "SubSGD iter. 236/499: loss=7.7334434520964805, w0=72.10000000000014, w1=17.068321890524597\n",
      "SubSGD iter. 237/499: loss=13.67834763354655, w0=72.80000000000014, w1=17.74001784670754\n",
      "SubSGD iter. 238/499: loss=11.47259578209598, w0=73.50000000000014, w1=18.192293485543434\n",
      "SubSGD iter. 239/499: loss=2.1297976855712193, w0=74.20000000000014, w1=17.56792192168834\n",
      "SubSGD iter. 240/499: loss=3.1559988766236415, w0=73.50000000000014, w1=17.01436886523663\n",
      "SubSGD iter. 241/499: loss=4.955634951579299, w0=74.20000000000014, w1=16.966786518964934\n",
      "SubSGD iter. 242/499: loss=0.8840740100208961, w0=74.90000000000015, w1=16.417356941047142\n",
      "SubSGD iter. 243/499: loss=4.771362317019047, w0=74.20000000000014, w1=16.693004016692903\n",
      "SubSGD iter. 244/499: loss=17.927601734141014, w0=74.90000000000015, w1=15.738574241413902\n",
      "SubSGD iter. 245/499: loss=1.5303779927170496, w0=74.20000000000014, w1=15.369620648226041\n",
      "SubSGD iter. 246/499: loss=0.4033038047244304, w0=73.50000000000014, w1=14.780618900836481\n",
      "SubSGD iter. 247/499: loss=8.827914280030939, w0=72.80000000000014, w1=14.941771868958444\n",
      "SubSGD iter. 248/499: loss=1.580356368741235, w0=72.10000000000014, w1=14.299753517926383\n",
      "SubSGD iter. 249/499: loss=3.360059269628202, w0=72.80000000000014, w1=12.847731184928001\n",
      "SubSGD iter. 250/499: loss=6.55169097199898, w0=72.10000000000014, w1=12.605188482863277\n",
      "SubSGD iter. 251/499: loss=7.475104628416503, w0=72.80000000000014, w1=13.484047224620813\n",
      "SubSGD iter. 252/499: loss=5.020444211483735, w0=72.10000000000014, w1=12.20617613503504\n",
      "SubSGD iter. 253/499: loss=4.165758123293983, w0=72.80000000000014, w1=12.163934478013278\n",
      "SubSGD iter. 254/499: loss=2.1926596675068524, w0=72.10000000000014, w1=12.70013225161497\n",
      "SubSGD iter. 255/499: loss=1.9725882606394691, w0=72.80000000000014, w1=12.286873075160521\n",
      "SubSGD iter. 256/499: loss=0.9793490298978185, w0=72.10000000000014, w1=13.032913283542962\n",
      "SubSGD iter. 257/499: loss=6.326503478706115, w0=72.80000000000014, w1=12.878718586064307\n",
      "SubSGD iter. 258/499: loss=0.5861194477828207, w0=72.10000000000014, w1=13.930705130021522\n",
      "SubSGD iter. 259/499: loss=5.281338034464298, w0=71.40000000000013, w1=14.245480558772757\n",
      "SubSGD iter. 260/499: loss=5.078657809695329, w0=72.10000000000014, w1=14.552412832851736\n",
      "SubSGD iter. 261/499: loss=4.456270313373771, w0=72.80000000000014, w1=13.888617697176986\n",
      "SubSGD iter. 262/499: loss=2.256534003072062, w0=73.50000000000014, w1=14.90598136397092\n",
      "SubSGD iter. 263/499: loss=10.381744147337955, w0=72.80000000000014, w1=14.681261710148078\n",
      "SubSGD iter. 264/499: loss=5.601075352375119, w0=73.50000000000014, w1=13.09470228299849\n",
      "SubSGD iter. 265/499: loss=5.02358852806357, w0=74.20000000000014, w1=13.845789747809036\n",
      "SubSGD iter. 266/499: loss=0.1537179108007649, w0=73.50000000000014, w1=15.003373151691827\n",
      "SubSGD iter. 267/499: loss=4.508811752308972, w0=74.20000000000014, w1=15.190495387761874\n",
      "SubSGD iter. 268/499: loss=0.223604127035415, w0=74.90000000000015, w1=14.300487588048766\n",
      "SubSGD iter. 269/499: loss=0.36065929698962407, w0=74.20000000000014, w1=14.20083210253631\n",
      "SubSGD iter. 270/499: loss=7.06293453039018, w0=74.90000000000015, w1=14.734468784081148\n",
      "SubSGD iter. 271/499: loss=0.8724055044690076, w0=75.60000000000015, w1=13.977060481414338\n",
      "SubSGD iter. 272/499: loss=5.434292812722077, w0=74.90000000000015, w1=14.176737361773823\n",
      "SubSGD iter. 273/499: loss=2.394181315415196, w0=75.60000000000015, w1=13.683260857652742\n",
      "SubSGD iter. 274/499: loss=0.8567460831963132, w0=74.90000000000015, w1=13.636832433810374\n",
      "SubSGD iter. 275/499: loss=10.611105791683514, w0=74.20000000000014, w1=13.597426939514182\n",
      "SubSGD iter. 276/499: loss=6.105953583138394, w0=74.90000000000015, w1=12.516328689980838\n",
      "SubSGD iter. 277/499: loss=4.54026628970567, w0=74.20000000000014, w1=13.554506992423397\n",
      "SubSGD iter. 278/499: loss=0.8673584378712604, w0=74.90000000000015, w1=13.433917013763317\n",
      "SubSGD iter. 279/499: loss=1.8088291564260146, w0=74.20000000000014, w1=13.684364776136842\n",
      "SubSGD iter. 280/499: loss=9.206815332053353, w0=73.50000000000014, w1=14.245198867192933\n",
      "SubSGD iter. 281/499: loss=7.686437898050357, w0=72.80000000000014, w1=13.834180407221085\n",
      "SubSGD iter. 282/499: loss=5.510081588154861, w0=72.10000000000014, w1=12.632854025500583\n",
      "SubSGD iter. 283/499: loss=1.8984707113858832, w0=71.40000000000013, w1=11.982692600384432\n",
      "SubSGD iter. 284/499: loss=9.021461445476334, w0=72.10000000000014, w1=13.166002898474094\n",
      "SubSGD iter. 285/499: loss=1.1171393075952665, w0=72.80000000000014, w1=13.72515241838587\n",
      "SubSGD iter. 286/499: loss=0.366414589910093, w0=72.10000000000014, w1=12.863464505714797\n",
      "SubSGD iter. 287/499: loss=1.6073091680181477, w0=71.40000000000013, w1=12.80866892173649\n",
      "SubSGD iter. 288/499: loss=1.0984155799860247, w0=72.10000000000014, w1=13.352850342241215\n",
      "SubSGD iter. 289/499: loss=5.537964939892092, w0=72.80000000000014, w1=13.452696810420527\n",
      "SubSGD iter. 290/499: loss=1.9077470749334822, w0=72.10000000000014, w1=13.480821704548598\n",
      "SubSGD iter. 291/499: loss=9.892431113696091, w0=72.80000000000014, w1=14.246036105795488\n",
      "SubSGD iter. 292/499: loss=9.28295369795778, w0=72.10000000000014, w1=13.481062727094384\n",
      "SubSGD iter. 293/499: loss=11.03544367740605, w0=72.80000000000014, w1=13.483930209864125\n",
      "SubSGD iter. 294/499: loss=7.099059569985393, w0=72.10000000000014, w1=14.280313999983395\n",
      "SubSGD iter. 295/499: loss=1.021449355614223, w0=71.40000000000013, w1=15.150072855406743\n",
      "SubSGD iter. 296/499: loss=0.6705332883320096, w0=70.70000000000013, w1=14.307492239157876\n",
      "SubSGD iter. 297/499: loss=7.591336182581003, w0=71.40000000000013, w1=13.536212837233757\n",
      "SubSGD iter. 298/499: loss=6.466613429377915, w0=72.10000000000014, w1=14.142834215361477\n",
      "SubSGD iter. 299/499: loss=0.12181128181002521, w0=72.80000000000014, w1=15.183458309066113\n",
      "SubSGD iter. 300/499: loss=7.38628350531053, w0=73.50000000000014, w1=15.54681432617836\n",
      "SubSGD iter. 301/499: loss=1.0534236733866464, w0=74.20000000000014, w1=13.600129437981487\n",
      "SubSGD iter. 302/499: loss=2.4464149843343463, w0=74.90000000000015, w1=12.423445113891386\n",
      "SubSGD iter. 303/499: loss=6.691188470233655, w0=74.20000000000014, w1=12.751083002811136\n",
      "SubSGD iter. 304/499: loss=2.328171024609034, w0=73.50000000000014, w1=12.115392308766486\n",
      "SubSGD iter. 305/499: loss=11.26108234645757, w0=74.20000000000014, w1=12.83746787721128\n",
      "SubSGD iter. 306/499: loss=3.6715526994754555, w0=74.90000000000015, w1=12.210650739064404\n",
      "SubSGD iter. 307/499: loss=7.128356691412762, w0=75.60000000000015, w1=12.198211817459962\n",
      "SubSGD iter. 308/499: loss=0.3690336905668232, w0=76.30000000000015, w1=12.403447551377363\n",
      "SubSGD iter. 309/499: loss=15.734131484428453, w0=75.60000000000015, w1=13.22026787490554\n",
      "SubSGD iter. 310/499: loss=1.5709902996934204, w0=74.90000000000015, w1=12.506832533331371\n",
      "SubSGD iter. 311/499: loss=2.025960741063841, w0=74.20000000000014, w1=12.955769604136393\n",
      "SubSGD iter. 312/499: loss=4.133364699982593, w0=74.90000000000015, w1=13.402786544211658\n",
      "SubSGD iter. 313/499: loss=6.270247855182404, w0=74.20000000000014, w1=14.105131567879635\n",
      "SubSGD iter. 314/499: loss=1.8132590002434341, w0=73.50000000000014, w1=12.676955749154613\n",
      "SubSGD iter. 315/499: loss=5.002945616985613, w0=74.20000000000014, w1=13.637763390467365\n",
      "SubSGD iter. 316/499: loss=4.289616096220271, w0=73.50000000000014, w1=13.884535467985538\n",
      "SubSGD iter. 317/499: loss=3.8711407562424114, w0=72.80000000000014, w1=14.89783467374992\n",
      "SubSGD iter. 318/499: loss=1.1957742172390198, w0=73.50000000000014, w1=14.457926474875293\n",
      "SubSGD iter. 319/499: loss=6.230336448066225, w0=74.20000000000014, w1=14.749280395859834\n",
      "SubSGD iter. 320/499: loss=4.204384949376291, w0=73.50000000000014, w1=14.024335480706874\n",
      "SubSGD iter. 321/499: loss=3.2476839415770797, w0=74.20000000000014, w1=13.529058727660585\n",
      "SubSGD iter. 322/499: loss=5.339331590399198, w0=73.50000000000014, w1=14.532785676877431\n",
      "SubSGD iter. 323/499: loss=5.434180855453761, w0=72.80000000000014, w1=14.663877222260787\n",
      "SubSGD iter. 324/499: loss=4.86318002484289, w0=73.50000000000014, w1=14.901209586672167\n",
      "SubSGD iter. 325/499: loss=10.849919853857287, w0=74.20000000000014, w1=14.561004376826729\n",
      "SubSGD iter. 326/499: loss=8.793904797233708, w0=73.50000000000014, w1=13.116126827259976\n",
      "SubSGD iter. 327/499: loss=6.351688775996308, w0=72.80000000000014, w1=13.80333421117732\n",
      "SubSGD iter. 328/499: loss=5.916203561025668, w0=73.50000000000014, w1=14.176760446773034\n",
      "SubSGD iter. 329/499: loss=4.774390514875812, w0=72.80000000000014, w1=14.73646740170838\n",
      "SubSGD iter. 330/499: loss=1.7528916117782671, w0=73.50000000000014, w1=14.314830432528495\n",
      "SubSGD iter. 331/499: loss=6.101218350639314, w0=72.80000000000014, w1=14.002798793443676\n",
      "SubSGD iter. 332/499: loss=4.268199526274202, w0=73.50000000000014, w1=13.605886378262737\n",
      "SubSGD iter. 333/499: loss=1.1279571751130817, w0=74.20000000000014, w1=14.37518564670822\n",
      "SubSGD iter. 334/499: loss=1.037067946718956, w0=73.50000000000014, w1=14.916360314866115\n",
      "SubSGD iter. 335/499: loss=0.5857205638704812, w0=72.80000000000014, w1=13.800674824630681\n",
      "SubSGD iter. 336/499: loss=6.211470543572048, w0=73.50000000000014, w1=13.444786654411471\n",
      "SubSGD iter. 337/499: loss=8.72957437588979, w0=72.80000000000014, w1=13.560940947453483\n",
      "SubSGD iter. 338/499: loss=3.0101478917513305, w0=72.10000000000014, w1=13.743580515405327\n",
      "SubSGD iter. 339/499: loss=4.6448395582967805, w0=72.80000000000014, w1=14.594568743014234\n",
      "SubSGD iter. 340/499: loss=2.7520853905020317, w0=73.50000000000014, w1=14.58728326024681\n",
      "SubSGD iter. 341/499: loss=0.7377411217624825, w0=72.80000000000014, w1=15.623296369207523\n",
      "SubSGD iter. 342/499: loss=2.937263581531461, w0=72.10000000000014, w1=16.27655434890946\n",
      "SubSGD iter. 343/499: loss=0.5062114374758124, w0=71.40000000000013, w1=14.956710561378912\n",
      "SubSGD iter. 344/499: loss=4.109430156681867, w0=72.10000000000014, w1=15.397318630578464\n",
      "SubSGD iter. 345/499: loss=0.87972879771133, w0=72.80000000000014, w1=14.039800638027074\n",
      "SubSGD iter. 346/499: loss=3.585082269665051, w0=72.10000000000014, w1=12.638955018620884\n",
      "SubSGD iter. 347/499: loss=7.303189463830023, w0=72.80000000000014, w1=12.367291193093466\n",
      "SubSGD iter. 348/499: loss=5.350747619526146, w0=73.50000000000014, w1=12.551821269678419\n",
      "SubSGD iter. 349/499: loss=5.888977545720834, w0=74.20000000000014, w1=12.914854078054272\n",
      "SubSGD iter. 350/499: loss=1.6815529639019928, w0=74.90000000000015, w1=14.147637721000235\n",
      "SubSGD iter. 351/499: loss=3.8614949466829387, w0=74.20000000000014, w1=13.273601711157188\n",
      "SubSGD iter. 352/499: loss=3.4216413487613124, w0=74.90000000000015, w1=13.622316367170312\n",
      "SubSGD iter. 353/499: loss=4.503712982737653, w0=74.20000000000014, w1=12.789618307133255\n",
      "SubSGD iter. 354/499: loss=4.208637892159629, w0=74.90000000000015, w1=13.741938553773357\n",
      "SubSGD iter. 355/499: loss=5.2471153092104785, w0=75.60000000000015, w1=13.084380129561707\n",
      "SubSGD iter. 356/499: loss=8.482855297529525, w0=74.90000000000015, w1=13.771587513479052\n",
      "SubSGD iter. 357/499: loss=0.8082606835095731, w0=75.60000000000015, w1=14.387769163686741\n",
      "SubSGD iter. 358/499: loss=9.88118462167894, w0=74.90000000000015, w1=14.510913400528546\n",
      "SubSGD iter. 359/499: loss=7.041107789528411, w0=74.20000000000014, w1=15.142798122732385\n",
      "SubSGD iter. 360/499: loss=7.31643286580983, w0=73.50000000000014, w1=14.050313746698823\n",
      "SubSGD iter. 361/499: loss=1.6264279869887304, w0=72.80000000000014, w1=12.164483867673024\n",
      "SubSGD iter. 362/499: loss=4.078272776739283, w0=73.50000000000014, w1=11.899566224620118\n",
      "SubSGD iter. 363/499: loss=8.145868538685761, w0=72.80000000000014, w1=12.32720807392647\n",
      "SubSGD iter. 364/499: loss=5.2052779396501165, w0=73.50000000000014, w1=13.638613043810723\n",
      "SubSGD iter. 365/499: loss=0.4712376200404833, w0=72.80000000000014, w1=12.353329171711657\n",
      "SubSGD iter. 366/499: loss=3.8420848456688077, w0=73.50000000000014, w1=11.52903821664317\n",
      "SubSGD iter. 367/499: loss=9.030050352342244, w0=74.20000000000014, w1=11.880820278780908\n",
      "SubSGD iter. 368/499: loss=11.187947524482375, w0=73.50000000000014, w1=12.160306485407922\n",
      "SubSGD iter. 369/499: loss=4.331181668021841, w0=74.20000000000014, w1=12.491189533144428\n",
      "SubSGD iter. 370/499: loss=4.135799137231579, w0=73.50000000000014, w1=13.034429508215842\n",
      "SubSGD iter. 371/499: loss=6.771511372253244, w0=72.80000000000014, w1=12.931536723662335\n",
      "SubSGD iter. 372/499: loss=0.4626778138724106, w0=73.50000000000014, w1=12.073568825967957\n",
      "SubSGD iter. 373/499: loss=5.291999661847754, w0=74.20000000000014, w1=12.260691062038005\n",
      "SubSGD iter. 374/499: loss=1.963912225788711, w0=73.50000000000014, w1=13.084506060566365\n",
      "SubSGD iter. 375/499: loss=3.9487008591651147, w0=72.80000000000014, w1=11.88398068525484\n",
      "SubSGD iter. 376/499: loss=1.8907801741314074, w0=73.50000000000014, w1=12.14019130415867\n",
      "SubSGD iter. 377/499: loss=3.9854772129761784, w0=72.80000000000014, w1=11.661305761320154\n",
      "SubSGD iter. 378/499: loss=4.518284740500931, w0=73.50000000000014, w1=10.932387678359877\n",
      "SubSGD iter. 379/499: loss=6.275601244032863, w0=74.20000000000014, w1=10.266789611307617\n",
      "SubSGD iter. 380/499: loss=7.058833025323757, w0=73.50000000000014, w1=10.890910701890162\n",
      "SubSGD iter. 381/499: loss=1.1118497640468235, w0=72.80000000000014, w1=10.845776807273543\n",
      "SubSGD iter. 382/499: loss=14.167568437598987, w0=73.50000000000014, w1=13.143945829328972\n",
      "SubSGD iter. 383/499: loss=7.84081404841568, w0=74.20000000000014, w1=13.48970487757481\n",
      "SubSGD iter. 384/499: loss=0.048531376063877474, w0=73.50000000000014, w1=13.21878078888792\n",
      "SubSGD iter. 385/499: loss=0.9922728046007734, w0=74.20000000000014, w1=13.411886868804197\n",
      "SubSGD iter. 386/499: loss=0.44055577230165, w0=73.50000000000014, w1=14.765743222614967\n",
      "SubSGD iter. 387/499: loss=4.455770708863646, w0=72.80000000000014, w1=15.270777988070602\n",
      "SubSGD iter. 388/499: loss=3.8614247607249865, w0=72.10000000000014, w1=15.730063454737206\n",
      "SubSGD iter. 389/499: loss=2.864328101106551, w0=71.40000000000013, w1=14.83159542033298\n",
      "SubSGD iter. 390/499: loss=1.8320949644941038, w0=72.10000000000014, w1=14.447183982707838\n",
      "SubSGD iter. 391/499: loss=3.726972753902899, w0=72.80000000000014, w1=14.371894874961242\n",
      "SubSGD iter. 392/499: loss=6.26414515043448, w0=73.50000000000014, w1=13.112019435743026\n",
      "SubSGD iter. 393/499: loss=4.500375506986472, w0=74.20000000000014, w1=13.109066729516497\n",
      "SubSGD iter. 394/499: loss=1.167387914846799, w0=73.50000000000014, w1=12.691580646836654\n",
      "SubSGD iter. 395/499: loss=4.461869864341438, w0=72.80000000000014, w1=12.67297482927119\n",
      "SubSGD iter. 396/499: loss=3.525600760680078, w0=73.50000000000014, w1=11.89970379669019\n",
      "SubSGD iter. 397/499: loss=7.823466110089775, w0=72.80000000000014, w1=12.501328305779744\n",
      "SubSGD iter. 398/499: loss=5.515673007733383, w0=73.50000000000014, w1=12.955959727335811\n",
      "SubSGD iter. 399/499: loss=10.08060856925605, w0=72.80000000000014, w1=13.281157976394113\n",
      "SubSGD iter. 400/499: loss=3.6173880254204605, w0=72.10000000000014, w1=13.862470260902166\n",
      "SubSGD iter. 401/499: loss=10.905641809702928, w0=72.80000000000014, w1=14.611110355536692\n",
      "SubSGD iter. 402/499: loss=1.4235940041659205, w0=73.50000000000014, w1=14.16217328473167\n",
      "SubSGD iter. 403/499: loss=4.868671071158857, w0=72.80000000000014, w1=14.837234204983579\n",
      "SubSGD iter. 404/499: loss=2.4562550961280465, w0=72.10000000000014, w1=13.993741333829286\n",
      "SubSGD iter. 405/499: loss=0.17248820720774916, w0=71.40000000000013, w1=14.262183030738257\n",
      "SubSGD iter. 406/499: loss=5.841181731127463, w0=72.10000000000014, w1=13.64751020185312\n",
      "SubSGD iter. 407/499: loss=9.942779188273548, w0=72.80000000000014, w1=13.466622625435177\n",
      "SubSGD iter. 408/499: loss=5.281785946260015, w0=73.50000000000014, w1=13.556557867899642\n",
      "SubSGD iter. 409/499: loss=2.7315041541043854, w0=74.20000000000014, w1=14.022842306252313\n",
      "SubSGD iter. 410/499: loss=1.5336068823107851, w0=74.90000000000015, w1=13.274245791429285\n",
      "SubSGD iter. 411/499: loss=1.8231883507601054, w0=75.60000000000015, w1=12.694380953616415\n",
      "SubSGD iter. 412/499: loss=3.327803675142988, w0=74.90000000000015, w1=11.6281783236902\n",
      "SubSGD iter. 413/499: loss=6.987702485674859, w0=74.20000000000014, w1=11.462665637225191\n",
      "SubSGD iter. 414/499: loss=6.115568118893464, w0=74.90000000000015, w1=12.032402944868117\n",
      "SubSGD iter. 415/499: loss=6.8582718144654535, w0=74.20000000000014, w1=12.226560197369963\n",
      "SubSGD iter. 416/499: loss=4.880873830139464, w0=73.50000000000014, w1=10.55178686771225\n",
      "SubSGD iter. 417/499: loss=0.37944138257451243, w0=72.80000000000014, w1=10.381524473944983\n",
      "SubSGD iter. 418/499: loss=1.298529500835997, w0=72.10000000000014, w1=10.591081761851825\n",
      "SubSGD iter. 419/499: loss=11.307318400532168, w0=72.80000000000014, w1=11.304992968621017\n",
      "SubSGD iter. 420/499: loss=2.4408453570340924, w0=72.10000000000014, w1=13.254645459176075\n",
      "SubSGD iter. 421/499: loss=0.3700777254652792, w0=71.40000000000013, w1=13.114393059685803\n",
      "SubSGD iter. 422/499: loss=0.4470388468479598, w0=70.70000000000013, w1=13.932145624488886\n",
      "SubSGD iter. 423/499: loss=1.6566837737937732, w0=70.00000000000013, w1=13.583996793249241\n",
      "SubSGD iter. 424/499: loss=0.9544206042563346, w0=69.30000000000013, w1=14.218664556729971\n",
      "SubSGD iter. 425/499: loss=1.200790422825186, w0=70.00000000000013, w1=12.994721539824875\n",
      "SubSGD iter. 426/499: loss=7.308036478422423, w0=70.70000000000013, w1=12.808994496515503\n",
      "SubSGD iter. 427/499: loss=10.241002291887213, w0=71.40000000000013, w1=13.201661484292792\n",
      "SubSGD iter. 428/499: loss=1.2890078357677481, w0=70.70000000000013, w1=12.283430224170116\n",
      "SubSGD iter. 429/499: loss=4.2523526761607116, w0=70.00000000000013, w1=13.263763149305392\n",
      "SubSGD iter. 430/499: loss=1.6758404670311506, w0=70.70000000000013, w1=12.479302496549652\n",
      "SubSGD iter. 431/499: loss=6.165724884621341, w0=71.40000000000013, w1=13.258220997381015\n",
      "SubSGD iter. 432/499: loss=15.768320829470056, w0=72.10000000000014, w1=13.71049663621691\n",
      "SubSGD iter. 433/499: loss=1.9145438749079204, w0=72.80000000000014, w1=14.248970800568193\n",
      "SubSGD iter. 434/499: loss=2.096865699627145, w0=73.50000000000014, w1=13.661955325500374\n",
      "SubSGD iter. 435/499: loss=2.982756217167008, w0=72.80000000000014, w1=13.952468302911395\n",
      "SubSGD iter. 436/499: loss=7.468821685808706, w0=73.50000000000014, w1=14.194370956211237\n",
      "SubSGD iter. 437/499: loss=0.2163865639143765, w0=74.20000000000014, w1=13.118127809232448\n",
      "SubSGD iter. 438/499: loss=6.881011765322455, w0=74.90000000000015, w1=14.139611053729517\n",
      "SubSGD iter. 439/499: loss=5.001375516116013, w0=74.20000000000014, w1=14.329322359479939\n",
      "SubSGD iter. 440/499: loss=2.5206243735251803, w0=73.50000000000014, w1=14.505946352592535\n",
      "SubSGD iter. 441/499: loss=8.13384010168864, w0=72.80000000000014, w1=15.15930477051415\n",
      "SubSGD iter. 442/499: loss=3.051261275507386, w0=73.50000000000014, w1=14.255978649289759\n",
      "SubSGD iter. 443/499: loss=3.9774279890445143, w0=72.80000000000014, w1=14.72442031986585\n",
      "SubSGD iter. 444/499: loss=1.3304628436048915, w0=73.50000000000014, w1=14.366158482927187\n",
      "SubSGD iter. 445/499: loss=5.32718996932946, w0=72.80000000000014, w1=14.859881169619435\n",
      "SubSGD iter. 446/499: loss=3.796606557466461, w0=73.50000000000014, w1=15.465916599891113\n",
      "SubSGD iter. 447/499: loss=1.4620122448689017, w0=74.20000000000014, w1=14.827622897342003\n",
      "SubSGD iter. 448/499: loss=1.176345405298079, w0=74.90000000000015, w1=15.689497435454776\n",
      "SubSGD iter. 449/499: loss=0.9882828309139811, w0=74.20000000000014, w1=16.136542066583033\n",
      "SubSGD iter. 450/499: loss=9.610734563651675, w0=73.50000000000014, w1=15.706354970597584\n",
      "SubSGD iter. 451/499: loss=4.228715658867287, w0=74.20000000000014, w1=14.96011582574675\n",
      "SubSGD iter. 452/499: loss=3.220234297590622, w0=74.90000000000015, w1=14.84598105534813\n",
      "SubSGD iter. 453/499: loss=0.4144356777078002, w0=75.60000000000015, w1=15.417606481631033\n",
      "SubSGD iter. 454/499: loss=7.553992724427744, w0=74.90000000000015, w1=13.722752132752758\n",
      "SubSGD iter. 455/499: loss=6.8458983666671, w0=75.60000000000015, w1=14.584543671428797\n",
      "SubSGD iter. 456/499: loss=0.010184754324505718, w0=76.30000000000015, w1=13.827135368761986\n",
      "SubSGD iter. 457/499: loss=2.1890132173049395, w0=75.60000000000015, w1=14.660111614442037\n",
      "SubSGD iter. 458/499: loss=14.848297668421047, w0=74.90000000000015, w1=14.650776849027629\n",
      "SubSGD iter. 459/499: loss=7.89677522322296, w0=74.20000000000014, w1=14.83273760503162\n",
      "SubSGD iter. 460/499: loss=11.20559220556811, w0=74.90000000000015, w1=14.869710974330077\n",
      "SubSGD iter. 461/499: loss=2.290461139561586, w0=75.60000000000015, w1=14.555436680863947\n",
      "SubSGD iter. 462/499: loss=9.041957119107778, w0=76.30000000000015, w1=14.88300435338641\n",
      "SubSGD iter. 463/499: loss=2.8751667382342134, w0=75.60000000000015, w1=15.328109419595146\n",
      "SubSGD iter. 464/499: loss=1.0492328931194947, w0=74.90000000000015, w1=14.732376975229885\n",
      "SubSGD iter. 465/499: loss=2.4373411383458574, w0=74.20000000000014, w1=14.834448125865855\n",
      "SubSGD iter. 466/499: loss=4.820718495676914, w0=73.50000000000014, w1=15.161871134056474\n",
      "SubSGD iter. 467/499: loss=0.17324005076792304, w0=74.20000000000014, w1=14.326166681552541\n",
      "SubSGD iter. 468/499: loss=7.447575666740207, w0=74.90000000000015, w1=14.831670904195828\n",
      "SubSGD iter. 469/499: loss=6.200467947316255, w0=74.20000000000014, w1=15.526281395788091\n",
      "SubSGD iter. 470/499: loss=9.322073416315206, w0=74.90000000000015, w1=14.646356773106477\n",
      "SubSGD iter. 471/499: loss=8.038690218806416, w0=75.60000000000015, w1=13.381696784083319\n",
      "SubSGD iter. 472/499: loss=2.2850693158477497, w0=74.90000000000015, w1=12.484330954369842\n",
      "SubSGD iter. 473/499: loss=0.3898379828849059, w0=75.60000000000015, w1=11.434699967090996\n",
      "SubSGD iter. 474/499: loss=6.177269785412172, w0=74.90000000000015, w1=12.230970351297469\n",
      "SubSGD iter. 475/499: loss=8.09627233300776, w0=74.20000000000014, w1=12.998050405709218\n",
      "SubSGD iter. 476/499: loss=5.064732527945623, w0=73.50000000000014, w1=12.80226009136836\n",
      "SubSGD iter. 477/499: loss=7.89890639613958, w0=74.20000000000014, w1=13.137937465232435\n",
      "SubSGD iter. 478/499: loss=2.0660371583421124, w0=74.90000000000015, w1=13.754119115440124\n",
      "SubSGD iter. 479/499: loss=0.569508581596935, w0=74.20000000000014, w1=13.155995104184266\n",
      "SubSGD iter. 480/499: loss=1.7976571795223748, w0=74.90000000000015, w1=12.822342002086161\n",
      "SubSGD iter. 481/499: loss=10.722599261969094, w0=75.60000000000015, w1=12.955165916935078\n",
      "SubSGD iter. 482/499: loss=3.540550371110413, w0=76.30000000000015, w1=12.682379340209335\n",
      "SubSGD iter. 483/499: loss=5.1711620024028235, w0=75.60000000000015, w1=10.93323898114083\n",
      "SubSGD iter. 484/499: loss=12.196961769101065, w0=74.90000000000015, w1=10.830064143118186\n",
      "SubSGD iter. 485/499: loss=8.190334617406855, w0=74.20000000000014, w1=11.354401190654634\n",
      "SubSGD iter. 486/499: loss=10.25989919442992, w0=73.50000000000014, w1=11.590447328865764\n",
      "SubSGD iter. 487/499: loss=5.927706760943494, w0=72.80000000000014, w1=11.50555123769569\n",
      "SubSGD iter. 488/499: loss=8.014196887792949, w0=73.50000000000014, w1=11.391505705782865\n",
      "SubSGD iter. 489/499: loss=0.6003341247295282, w0=72.80000000000014, w1=10.884326677500308\n",
      "SubSGD iter. 490/499: loss=6.00858752353934, w0=72.10000000000014, w1=11.769107311296995\n",
      "SubSGD iter. 491/499: loss=3.742386421559033, w0=72.80000000000014, w1=11.349418785174278\n",
      "SubSGD iter. 492/499: loss=8.567369916128058, w0=72.10000000000014, w1=11.289412173748207\n",
      "SubSGD iter. 493/499: loss=2.8738710116822475, w0=71.40000000000013, w1=11.88967145349746\n",
      "SubSGD iter. 494/499: loss=5.9991886857058105, w0=70.70000000000013, w1=12.081417772084967\n",
      "SubSGD iter. 495/499: loss=3.4501026185758974, w0=71.40000000000013, w1=11.716605409110649\n",
      "SubSGD iter. 496/499: loss=1.489145248883986, w0=70.70000000000013, w1=11.134528532740005\n",
      "SubSGD iter. 497/499: loss=4.508381507853883, w0=71.40000000000013, w1=11.978601539146927\n",
      "SubSGD iter. 498/499: loss=7.174034169917377, w0=72.10000000000014, w1=11.694961926244709\n",
      "SubSGD iter. 499/499: loss=1.457729057685178, w0=71.40000000000013, w1=12.319509311935253\n",
      "SubSGD: execution time=0.018 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6613d8ae7a654d14a180c5ead91ac305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
